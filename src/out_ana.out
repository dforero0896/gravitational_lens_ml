
Not using GPU.
No GPU found
Physical CPU found. Num Physical CPUs Available:  1
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Logical CPU found. Num logical CPUs Available:  1
[LogicalDevice(name='/job:localhost/replica:0/task:0/device:CPU:0', device_type='CPU')]

Configuration file:

Section: general
  workdir = /home/epfl/variu/phd/gravitational_lens_ml
  train_multiband = /home/epfl/dforero/gravitational_lens_ml/data/train_multiband_noclip_bin
  use_gpu = 1
Section: trainparams
  test_fraction = 0.33
  batch_size = 32
  subsample_train = 1000
  epochs = 35
  n = 3
  resnetversion = 1
  augment_train_data = 0
Section: bands
  vis0 = True
  nir1 = False
  nir2 = False
  nir3 = False
Project directory: /home/epfl/variu/phd/gravitational_lens_ml
The shape of the image catalog: (100009, 26)

The number of objects in the whole training sample is:  66993
The number of objects in the whole validation sample is:  32998
The test fraction is:  0.33
The number of objects in the training subsample is:  1000
The number of objects in the validation subsample is:  492
The number of training steps is:  31
The number of validation steps is:  15
The bands are:  [True, False, False, False]
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 200, 200, 1) 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 200, 200, 16) 160         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 200, 200, 16) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 200, 200, 16) 2320        activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 200, 200, 16) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          conv2d_2[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 200, 200, 16) 0           activation[0][0]                 
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 200, 200, 16) 0           add[0][0]                        
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 200, 200, 16) 2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 200, 200, 16) 64          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 200, 200, 16) 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 200, 200, 16) 2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          conv2d_4[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 200, 200, 16) 0           activation_2[0][0]               
                                                                 batch_normalization_4[0][0]      
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 200, 200, 16) 0           add_1[0][0]                      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 200, 200, 16) 0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 200, 200, 16) 64          conv2d_6[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 200, 200, 16) 0           activation_4[0][0]               
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 200, 200, 16) 0           add_2[0][0]                      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 100, 100, 32) 4640        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 100, 100, 32) 128         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 100, 100, 32) 0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 100, 100, 32) 9248        activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 100, 100, 32) 544         activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 100, 100, 32) 128         conv2d_8[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, 100, 100, 32) 0           conv2d_9[0][0]                   
                                                                 batch_normalization_8[0][0]      
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 100, 100, 32) 0           add_3[0][0]                      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 100, 100, 32) 9248        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 100, 100, 32) 128         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 100, 100, 32) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 100, 100, 32) 9248        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 100, 100, 32) 128         conv2d_11[0][0]                  
__________________________________________________________________________________________________
add_4 (Add)                     (None, 100, 100, 32) 0           activation_8[0][0]               
                                                                 batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 100, 100, 32) 0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 100, 100, 32) 9248        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 100, 100, 32) 128         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 100, 100, 32) 0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 100, 100, 32) 9248        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 100, 100, 32) 128         conv2d_13[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 100, 100, 32) 0           activation_10[0][0]              
                                                                 batch_normalization_12[0][0]     
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 100, 100, 32) 0           add_5[0][0]                      
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 50, 50, 64)   18496       activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 50, 50, 64)   256         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 50, 50, 64)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 50, 50, 64)   36928       activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 50, 50, 64)   2112        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 50, 50, 64)   256         conv2d_15[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 50, 50, 64)   0           conv2d_16[0][0]                  
                                                                 batch_normalization_14[0][0]     
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 50, 50, 64)   0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 50, 50, 64)   36928       activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 50, 50, 64)   256         conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 50, 50, 64)   0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 50, 50, 64)   36928       activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 50, 50, 64)   256         conv2d_18[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 50, 50, 64)   0           activation_14[0][0]              
                                                                 batch_normalization_16[0][0]     
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 50, 50, 64)   0           add_7[0][0]                      
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 50, 50, 64)   36928       activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 50, 50, 64)   256         conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 50, 50, 64)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 50, 50, 64)   36928       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 50, 50, 64)   256         conv2d_20[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 50, 50, 64)   0           activation_16[0][0]              
                                                                 batch_normalization_18[0][0]     
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 50, 50, 64)   0           add_8[0][0]                      
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 6, 6, 64)     0           activation_18[0][0]              
__________________________________________________________________________________________________
flatten (Flatten)               (None, 2304)         0           average_pooling2d[0][0]          
__________________________________________________________________________________________________
dense (Dense)                   (None, 1)            2305        flatten[0][0]                    
==================================================================================================
Total params: 275,809
Trainable params: 274,433
Non-trainable params: 1,376
__________________________________________________________________________________________________
history keys:
 dict_keys(['loss', 'tp', 'fp', 'tn', 'fn', 'acc', 'auc', 'val_loss', 'val_tp', 'val_fp', 'val_tn', 'val_fn', 'val_acc', 'val_auc', 'lr'])
492/492 - 8s
[0.   0.02 0.04 0.04 0.06 0.06 0.08 0.08 0.1  0.1  0.14 0.14 0.16 0.16
 0.18 0.18 0.2  0.2  0.22 0.22 0.24 0.24 0.26 0.26 0.28 0.28 0.3  0.3
 0.32 0.32 0.34 0.34 0.36 0.36 0.38 0.38 0.4  0.4  0.42 0.42 0.44 0.44
 0.46 0.46 0.48 0.48 0.5  0.5  0.52 0.52 0.54 0.54 0.56 0.56 0.58 0.58
 0.6  0.6  0.62 0.62 0.64 0.64 0.66 0.66 0.72 0.72 0.74 0.74 0.78 0.78
 0.8  0.8  0.82 0.82 0.84 0.84 0.86 0.86 0.88 0.88 0.9  0.9  0.94 0.94
 0.96 0.96 0.98 0.98 1.   1.  ]
[0.         0.         0.         0.0361991  0.0361991  0.04524887
 0.04524887 0.04977376 0.04977376 0.11538462 0.11538462 0.14253394
 0.14253394 0.19683258 0.19683258 0.19909502 0.19909502 0.21266968
 0.21266968 0.24208145 0.24208145 0.26470588 0.26470588 0.26923077
 0.26923077 0.2918552  0.2918552  0.30769231 0.30769231 0.32579186
 0.32579186 0.33257919 0.33257919 0.3800905  0.3800905  0.41176471
 0.41176471 0.42533937 0.42533937 0.42986425 0.42986425 0.4321267
 0.4321267  0.43438914 0.43438914 0.45022624 0.45022624 0.46606335
 0.46606335 0.47511312 0.47511312 0.50678733 0.50678733 0.52262443
 0.52262443 0.5678733  0.5678733  0.58823529 0.58823529 0.59276018
 0.59276018 0.59728507 0.59728507 0.66289593 0.66289593 0.69909502
 0.69909502 0.71266968 0.71266968 0.71719457 0.71719457 0.71945701
 0.71945701 0.72171946 0.72171946 0.81221719 0.81221719 0.85520362
 0.85520362 0.88461538 0.88461538 0.92081448 0.92081448 0.94343891
 0.94343891 0.97963801 0.97963801 0.99321267 0.99321267 1.        ]
