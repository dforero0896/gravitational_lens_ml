{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:22.004706Z",
     "start_time": "2019-11-16T17:39:21.162804Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tifffile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cd232d5acbb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtifffile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAsymmetricPercentileInterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogStretch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinMaxInterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tifffile'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tifffile\n",
    "import sys\n",
    "from astropy.visualization import AsymmetricPercentileInterval, LogStretch, MinMaxInterval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:22.010699Z",
     "start_time": "2019-11-16T17:39:22.006691Z"
    }
   },
   "outputs": [],
   "source": [
    "WORKDIR='/home/daniel/gdrive/EPFL/2019-2020/MachineLearning/Project/gravitational_lens_ml'\n",
    "SRC = os.path.join(WORKDIR, 'src')\n",
    "DATA = os.path.join(WORKDIR,'data')\n",
    "RESULTS = os.path.join(WORKDIR, 'results')\n",
    "TRAIN = os.path.join(DATA, 'datapack2.0train/Public')\n",
    "TEST = os.path.join(DATA, 'datapack2.0test/Public')\n",
    "TRAIN_MULTIBAND = os.path.join(DATA, 'train_multiband')\n",
    "TEST_MULTIBAND = os.path.join(DATA, 'test_multiband')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:22.607859Z",
     "start_time": "2019-11-16T17:39:22.012628Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9fb2f903b411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_catalog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'catalog/image_catalog2.0train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_catalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_catalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# No effective magnification for 11182 records.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DATA' is not defined"
     ]
    }
   ],
   "source": [
    "image_catalog = pd.read_csv(os.path.join(DATA, 'catalog/image_catalog2.0train.csv'), comment='#', index_col=0)\n",
    "print(image_catalog.shape)\n",
    "display(image_catalog.isna().sum(axis=0))\n",
    "# No effective magnification for 11182 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:23.219449Z",
     "start_time": "2019-11-16T17:39:22.609822Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TRAIN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-70c2ad6c6fa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mid_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelimiters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mid_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfile_id_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_file_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfile_id_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_file_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_existing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TRAIN' is not defined"
     ]
    }
   ],
   "source": [
    "band = 'EUC_VIS'\n",
    "def get_file_id(filename, delimiters = '_|\\.|-'):\n",
    "    id_ = [int(s) for s in re.split(delimiters, filename) if s.isdigit()][0]\n",
    "    return id_\n",
    "file_id_train = np.array([get_file_id(f) for f in os.listdir(os.path.join(TRAIN, band))], dtype=int)\n",
    "file_id_test = np.array([get_file_id(f) for f in os.listdir(os.path.join(TEST, band))], dtype=int)\n",
    "def check_existing_files(band, set_):\n",
    "    for ID in image_catalog.ID:\n",
    "        if not os.path.isfile(os.path.join(set_, band,'image%s-%i.fits'%(band, ID))):\n",
    "            print('File image%s-%i.fits does not exist in set.'%(band, ID))\n",
    "missing_img =  np.setdiff1d(image_catalog.ID.values, file_id_train, assume_unique=False)\n",
    "print(file_id_train.shape)\n",
    "print(missing_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:23.227899Z",
     "start_time": "2019-11-16T17:39:23.221329Z"
    }
   },
   "outputs": [],
   "source": [
    "image_catalog['is_lens'] = (image_catalog['mag_lens'] > 1.2) & (image_catalog['n_sources'] != 0)\n",
    "print('Number of lenses: %i'%image_catalog['is_lens'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:23.282280Z",
     "start_time": "2019-11-16T17:39:23.229729Z"
    }
   },
   "outputs": [],
   "source": [
    "image_catalog['img_exists'] = True\n",
    "image_catalog['img_exists'].loc[image_catalog['ID'].isin(missing_img)] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:23.600420Z",
     "start_time": "2019-11-16T17:39:23.284578Z"
    }
   },
   "outputs": [],
   "source": [
    "image_catalog = image_catalog.drop_duplicates('ID')\n",
    "image_catalog[['ID',\n",
    "               'is_lens']][image_catalog['img_exists']].to_csv(os.path.join(\n",
    "                   RESULTS, 'lens_id_labels.csv'),\n",
    "                                                               index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:23.962685Z",
     "start_time": "2019-11-16T17:39:23.601812Z"
    }
   },
   "outputs": [],
   "source": [
    "import aplpy \n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from reproject import reproject_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:24.006789Z",
     "start_time": "2019-11-16T17:39:23.963959Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_image_filename_from_id(id_, band, set_ = TRAIN, ext = 'fits'):\n",
    "    fname = os.path.join(set_, '{0}/image{0}-{1}.{2}'.format(band, id_, ext))\n",
    "    return fname\n",
    "def plot_all_bands_from_id(id_):\n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "    bands = ['EUC_VIS', 'EUC_H', 'EUC_Y', 'EUC_J']\n",
    "    fitsfigs = []\n",
    "    data = []\n",
    "    for i, band in enumerate(bands):\n",
    "        with fits.open(get_image_filename_from_id(id_, band)) as hdu:\n",
    "            data.append(hdu[0].data)\n",
    "        fitsfigs.append(aplpy.FITSFigure(data[i], figure=fig, subplot=(1,4,i+1)))\n",
    "        fitsfigs[i].show_colorscale()\n",
    "        fitsfigs[i].set_theme('preety')\n",
    "        fitsfigs[i].set_title(band)\n",
    "        fitsfigs[i].add_colorbar()\n",
    "    fig.tight_layout() \n",
    "with fits.open(get_image_filename_from_id(290000, 'EUC_VIS')) as hdu1:\n",
    "    with fits.open(get_image_filename_from_id(290000, 'EUC_H')) as hdu2:\n",
    "        data1 = hdu1[0].data\n",
    "        data2 = hdu2[0].data\n",
    "        data2_reprojected, data2_footprint = reproject_interp(hdu2[0], hdu1[0].header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:27.616000Z",
     "start_time": "2019-11-16T17:39:24.008260Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_all_bands_from_id(270610)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine bands into `tiff` and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:27.625566Z",
     "start_time": "2019-11-16T17:39:27.617581Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_image(id_, set_, bands = ['EUC_VIS', 'EUC_H', 'EUC_J', 'EUC_Y'], img_size=200, scale = 100):\n",
    "    tables = []\n",
    "    data = np.empty((img_size, img_size, len(bands)))\n",
    "    for i, band in enumerate(bands):\n",
    "        tables.append(fits.open(get_image_filename_from_id(id_, band)))\n",
    "        if band != 'EUC_VIS':\n",
    "            band_data, data_footprint = reproject_interp(tables[i][0], tables[0][0].header)\n",
    "        else:\n",
    "            band_data = tables[0][0].data\n",
    "        band_data[np.isnan(band_data)] = 0.\n",
    "        interval = AsymmetricPercentileInterval(0.25, 99.75, n_samples=10000)\n",
    "        vmin, vmax = interval.get_limits(band_data)\n",
    "        stretch = MinMaxInterval() +  LogStretch()\n",
    "        data[:,:,i] = stretch(((np.clip(band_data, vmin*(-0.7), vmax))/(vmax)))\n",
    "    for t in tables:\n",
    "        t.close()\n",
    "    return data.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:28.276988Z",
     "start_time": "2019-11-16T17:39:27.627318Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = build_image(270210, TRAIN)\n",
    "print(sys.getsizeof(img))\n",
    "for i in range(4):\n",
    "    plt.figure()\n",
    "    print(np.min(img[:,:,i]), np.max(img[:,:,i]))\n",
    "    a = plt.imshow((img[:,:,i]))\n",
    "print(image_catalog.loc[image_catalog['ID']==270210]['is_lens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare preprocessing with Log + Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:28.283016Z",
     "start_time": "2019-11-16T17:39:28.278292Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_image_noprocess(id_, set_, bands = ['EUC_VIS', 'EUC_H', 'EUC_J', 'EUC_Y'], img_size=200, scale = 100):\n",
    "    tables = []\n",
    "    data = np.empty((img_size, img_size, len(bands)))\n",
    "    for i, band in enumerate(bands):\n",
    "        tables.append(fits.open(get_image_filename_from_id(id_, band)))\n",
    "        if band != 'EUC_VIS':\n",
    "            band_data, data_footprint = reproject_interp(tables[i][0], tables[0][0].header)\n",
    "        else:\n",
    "            band_data = tables[0][0].data\n",
    "        band_data[np.isnan(band_data)] = 0.\n",
    "        norm =  LogStretch()\n",
    "        data[:,:,i] = norm(band_data)\n",
    "    for t in tables:\n",
    "        t.close()\n",
    "    return data.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:28.483261Z",
     "start_time": "2019-11-16T17:39:28.285080Z"
    }
   },
   "outputs": [],
   "source": [
    "test_id = 270210\n",
    "img = build_image(test_id, TRAIN)\n",
    "img_nopr = build_image_noprocess(test_id, TRAIN)\n",
    "def plot_slice(image, slice_ratio, axis=0):\n",
    "    '''Plot a single slice of a picture.\n",
    "    \n",
    "    image: Image to plot.\n",
    "    slice_ratio: float from 0 to 1 where 0 is the top slice, and 1 is the last slice.\n",
    "    axis: 0 or 1 to show horizontal or vertical slices'''\n",
    "    \n",
    "    index = int(image.shape[axis] * slice_ratio)\n",
    "    slice_ = image[index]\n",
    "    plt.plot(slice_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:28.737513Z",
     "start_time": "2019-11-16T17:39:28.485029Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_slice(img, 0.5)\n",
    "plt.figure()\n",
    "plot_slice(img_nopr, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:28.742406Z",
     "start_time": "2019-11-16T17:39:28.739114Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_slice_stack(image, axis=0):\n",
    "    '''Plot a single slice of a picture.\n",
    "    \n",
    "    image: Image to plot.'''\n",
    "    \n",
    "    slice_ = np.sum(image, axis=axis)\n",
    "    print(slice_.shape)\n",
    "    plt.plot(slice_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:28.995866Z",
     "start_time": "2019-11-16T17:39:28.743580Z"
    }
   },
   "outputs": [],
   "source": [
    "axis = 0\n",
    "plot_slice_stack(img, axis = axis)\n",
    "plt.figure()\n",
    "plot_slice_stack(img_nopr, axis = axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:30.064046Z",
     "start_time": "2019-11-16T17:39:28.997458Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.debugging.set_log_device_placement(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:30.077890Z",
     "start_time": "2019-11-16T17:39:30.065609Z"
    }
   },
   "outputs": [],
   "source": [
    "img = tifffile.imread(DATA+'/train_multiband/image_299896_multiband.tiff')\n",
    "def flatten_by_channel(original_image):\n",
    "    \"\"\"preprocess the image.\"\"\"\n",
    "    n_channels = original_image.shape[-1]\n",
    "    processed_image = original_image.reshape(-1,n_channels)\n",
    "    return processed_image.astype(np.float32) #Overflow if using unsigned int\n",
    "flat_img = flatten_by_channel(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:30.404685Z",
     "start_time": "2019-11-16T17:39:30.079170Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(whiten=False)\n",
    "std_flat_img = scaler.fit_transform(flat_img)\n",
    "pca.fit(std_flat_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:30.619548Z",
     "start_time": "2019-11-16T17:39:30.406776Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.bar(range(len(pca.explained_variance_ratio_)), pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:30.626723Z",
     "start_time": "2019-11-16T17:39:30.620822Z"
    }
   },
   "outputs": [],
   "source": [
    "pca_flat_img = pca.fit_transform(std_flat_img)\n",
    "pca_image = pca_flat_img.reshape((img.shape[0], img.shape[1], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:31.079436Z",
     "start_time": "2019-11-16T17:39:30.628037Z"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 2, figsize = (7, 7))\n",
    "for i, a in enumerate(ax.ravel()):\n",
    "    a.imshow(pca_image[:,:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance Matrix between colors\n",
    "See, that it is almost diagonal. Not surprising that PC's are almost the same as the priginal colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:31.201525Z",
     "start_time": "2019-11-16T17:39:31.080590Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.cov(flat_img.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test  CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:31.212816Z",
     "start_time": "2019-11-16T17:39:31.202742Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, Iterator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:31.216125Z",
     "start_time": "2019-11-16T17:39:31.213928Z"
    }
   },
   "outputs": [],
   "source": [
    "# From Tensorflow examples\n",
    "batch_size = 24\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 200\n",
    "IMG_WIDTH = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:31.294029Z",
     "start_time": "2019-11-16T17:39:31.217544Z"
    }
   },
   "outputs": [],
   "source": [
    "lens_df = pd.read_csv(os.path.join(RESULTS, 'lens_id_labels.csv'), index_col = 0)\n",
    "def build_generator_dataframe(id_label_df, directory = TRAIN_MULTIBAND):\n",
    "    files = os.listdir(directory)\n",
    "    ids = [\n",
    "        get_file_id(filename)\n",
    "        for filename in files\n",
    "    ]\n",
    "    df = pd.DataFrame()\n",
    "    df['filenames'] = files\n",
    "    df['labels'] = id_label_df.loc[ids, 'is_lens'].values.astype(int)\n",
    "    df['ID'] = ids\n",
    "    return df\n",
    "local_test_df = build_generator_dataframe(lens_df, TRAIN_MULTIBAND)\n",
    "train_df, val_df = train_test_split(local_test_df, test_size=0.1, random_state=42)\n",
    "total_train = len(train_df)\n",
    "total_val = len(val_df)\n",
    "display(local_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:31.538360Z",
     "start_time": "2019-11-16T17:39:31.295280Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', \n",
    "           input_shape=(IMG_HEIGHT, IMG_WIDTH ,4)),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:31.584740Z",
     "start_time": "2019-11-16T17:39:31.539619Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:31.600647Z",
     "start_time": "2019-11-16T17:39:31.586243Z"
    }
   },
   "outputs": [],
   "source": [
    "class TiffImageDataGenerator(ImageDataGenerator):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(TiffImageDataGenerator, self).__init__(*args, **kwargs)\n",
    "    def get_input(self, path):\n",
    "        img = tifffile.imread(path)\n",
    "        return img\n",
    "    def image_generator_dataframe(self,dataframe,\n",
    "                              directory='',\n",
    "                              x_col='filename',\n",
    "                              y_col='class',\n",
    "                              batch_size=64,\n",
    "                              validation=False):\n",
    "        files = dataframe[x_col].values\n",
    "        while True:\n",
    "            # Select files (paths/indices) for the batch\n",
    "            batch_paths = np.random.choice(a=files, size=batch_size)\n",
    "            batch_input = []\n",
    "            batch_output = []\n",
    "\n",
    "            # Read in each input, perform preprocessing and get labels\n",
    "            for input_path in batch_paths:\n",
    "                input = self.get_input(os.path.join(directory, input_path))\n",
    "                output = dataframe[dataframe[x_col] == input_path][y_col].values[0]\n",
    "                if self.preprocessing_function:\n",
    "                    input = self.preprocessing_function(input)\n",
    "                if not validation:\n",
    "                    input = self.random_transform(input)\n",
    "                batch_input += [input]\n",
    "                batch_output += [output]\n",
    "            # Return a tuple of (input,output) to feed the network\n",
    "            batch_x = np.array(batch_input)\n",
    "            batch_y = np.array(batch_output)\n",
    "\n",
    "            yield (batch_x, batch_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:31.607774Z",
     "start_time": "2019-11-16T17:39:31.602685Z"
    }
   },
   "outputs": [],
   "source": [
    "image_data_gen_train = TiffImageDataGenerator(featurewise_center=False,\n",
    "                                          samplewise_center=False,\n",
    "                                          featurewise_std_normalization=False,\n",
    "                                          samplewise_std_normalization=False,\n",
    "                                          zca_whitening=False,\n",
    "                                          zca_epsilon=1e-06,\n",
    "                                          rotation_range=90,\n",
    "                                          width_shift_range=0.0,\n",
    "                                          height_shift_range=0.0,\n",
    "                                          brightness_range=(0.8, 1.1),\n",
    "                                          shear_range=0.0,\n",
    "                                          zoom_range=(0.9, 1.1),\n",
    "                                          channel_shift_range=0.0,\n",
    "                                          fill_mode='wrap',\n",
    "                                          cval=0.0,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True,\n",
    "                                          rescale=None,\n",
    "                                          preprocessing_function=None,\n",
    "                                          data_format='channels_last',\n",
    "                                          dtype='float32')\n",
    "image_data_gen_val = TiffImageDataGenerator(dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:32.242767Z",
     "start_time": "2019-11-16T17:39:31.610128Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_gen = image_data_gen_train.image_generator_dataframe(train_df,\n",
    "                                  directory=TRAIN_MULTIBAND,\n",
    "                                  x_col='filenames',\n",
    "                                 y_col='labels', batch_size = 1, validation=False)\n",
    "val_data_gen = image_data_gen_val.image_generator_dataframe(train_df,\n",
    "                                  directory=TRAIN_MULTIBAND,\n",
    "                                  x_col='filenames',\n",
    "                                 y_col='labels', batch_size = 1, validation=True)\n",
    "fig, ax = plt.subplots(1,6, figsize = (15, 2.5))\n",
    "for a in ax.ravel():\n",
    "    img, label = next(train_data_gen)\n",
    "    a.imshow(img[0][:,:,2])\n",
    "    a.set_xlabel(label[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment non-lens sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:32.256341Z",
     "start_time": "2019-11-16T17:39:32.244288Z"
    }
   },
   "outputs": [],
   "source": [
    "no_lens_df = local_test_df[local_test_df['labels'] == 0]\n",
    "display(no_lens_df.head())\n",
    "print('Non-lens original sample size: %s'%len(no_lens_df))\n",
    "print('Non-lens original sample size: %s'%)\n",
    "print('Total original sample size: %s'%len(lens_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T19:15:03.784856Z",
     "start_time": "2019-11-16T19:15:03.770984Z"
    }
   },
   "outputs": [],
   "source": [
    "augment_nolens = TiffImageDataGenerator(featurewise_center=False,\n",
    "                                          samplewise_center=False,\n",
    "                                          featurewise_std_normalization=False,\n",
    "                                          samplewise_std_normalization=False,\n",
    "                                          zca_whitening=False,\n",
    "                                          zca_epsilon=1e-06,\n",
    "                                          rotation_range=20,\n",
    "                                          width_shift_range=0.0,\n",
    "                                          height_shift_range=0.0,\n",
    "                                          brightness_range=(0.8, 1.1),\n",
    "                                          shear_range=0.0,\n",
    "                                          zoom_range=(0.9, 1),\n",
    "                                          channel_shift_range=0.0,\n",
    "                                          fill_mode='wrap',\n",
    "                                          cval=0.0,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True,\n",
    "                                          rescale=None,\n",
    "                                          preprocessing_function=None,\n",
    "                                          data_format='channels_last',\n",
    "                                          dtype='float32')\n",
    "augment_nolens_gen = augment_nolens.image_generator_dataframe(no_lens_df,\n",
    "                                  directory=TRAIN_MULTIBAND,\n",
    "                                  x_col='filenames',\n",
    "                                 y_col='labels', batch_size = 1, validation=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T19:15:24.762620Z",
     "start_time": "2019-11-16T19:15:23.862194Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 8\n",
    "fig, ax = plt.subplots(1,i, figsize = (2.5*i, 2.5))\n",
    "for a in ax.ravel():\n",
    "    img, label = next(augment_nolens_gen)\n",
    "    a.imshow(img[0][:,:,3])\n",
    "    a.set_xlabel(label[0])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T19:21:58.764305Z",
     "start_time": "2019-11-16T19:21:58.015989Z"
    }
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(os.path.join(RESULTS, 'simple_cnn.h5'))\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:39:59.884226Z",
     "start_time": "2019-11-16T17:39:33.932153Z"
    }
   },
   "outputs": [],
   "source": [
    "loss, acc = new_model.evaluate_generator(val_data_gen, steps = 1000, use_multiprocessing=False, verbose  = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:40:00.194042Z",
     "start_time": "2019-11-16T17:39:59.886160Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = new_model.predict_generator(augment_nolens_gen, steps = 10)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:40:00.214264Z",
     "start_time": "2019-11-16T17:40:00.195574Z"
    }
   },
   "outputs": [],
   "source": [
    "next(augment_nolens_gen)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T17:40:00.333339Z",
     "start_time": "2019-11-16T17:40:00.215787Z"
    }
   },
   "outputs": [],
   "source": [
    "random_prediction = new_model.predict(np.random.random(200*200*4).reshape(200, 200, 4)[None, :, :, :])\n",
    "print('The prediction on random noise is: %.2f'%random_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T19:22:38.335239Z",
     "start_time": "2019-11-16T19:22:38.326230Z"
    }
   },
   "outputs": [],
   "source": [
    "help(tifffile.imwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
