GPU found. Num GPUs Available:  2
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]
Logical GPU found. Num logical GPUs Available:  2
[LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:0', device_type='GPU'), LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:1', device_type='GPU')]
Physical CPU found. Num Physical CPUs Available:  1
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Logical CPU found. Num logical CPUs Available:  1
[LogicalDevice(name='/job:localhost/replica:0/task:0/device:CPU:0', device_type='CPU')]

Configuration file:

Section: general
  workdir = /home/epfl/variu/phd/gravitational_lens_ml
  train_multiband = /home/epfl/dforero/gravitational_lens_ml/data/train_multiband_noclip_bin
  use_gpu = 1
Section: trainparams
  test_fraction = 0.33
  batch_size = 10
  subsample_train = 1000
  epochs = 200
  n = 3
  resnetversion = 1
  augment_train_data = 0
  data_bias = raw
Section: bands
  vis0 = 1
  nir1 = 0
  nir2 = 0
  nir3 = 0
Project directory: /home/epfl/variu/phd/gravitational_lens_ml
The shape of the image catalog: (100009, 26)

The number of objects in the whole training sample is:  66993
The number of objects in the whole validation sample is:  32998
The test fraction is:  0.33
The number of objects in the training subsample is:  1000
The number of objects in the validation subsample is:  492
The number of training steps is:  100
The number of validation steps is:  49
The bands are:  [True, False, False, False]
Learning rate:  0.001
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 200, 200, 1) 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 200, 200, 16) 160         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 200, 200, 16) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 200, 200, 16) 2320        activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 200, 200, 16) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          conv2d_2[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 200, 200, 16) 0           activation[0][0]                 
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 200, 200, 16) 0           add[0][0]                        
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 200, 200, 16) 2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 200, 200, 16) 64          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 200, 200, 16) 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 200, 200, 16) 2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          conv2d_4[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 200, 200, 16) 0           activation_2[0][0]               
                                                                 batch_normalization_4[0][0]      
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 200, 200, 16) 0           add_1[0][0]                      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 200, 200, 16) 0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 200, 200, 16) 64          conv2d_6[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 200, 200, 16) 0           activation_4[0][0]               
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 200, 200, 16) 0           add_2[0][0]                      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 100, 100, 32) 4640        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 100, 100, 32) 128         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 100, 100, 32) 0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 100, 100, 32) 9248        activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 100, 100, 32) 544         activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 100, 100, 32) 128         conv2d_8[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, 100, 100, 32) 0           conv2d_9[0][0]                   
                                                                 batch_normalization_8[0][0]      
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 100, 100, 32) 0           add_3[0][0]                      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 100, 100, 32) 9248        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 100, 100, 32) 128         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 100, 100, 32) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 100, 100, 32) 9248        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 100, 100, 32) 128         conv2d_11[0][0]                  
__________________________________________________________________________________________________
add_4 (Add)                     (None, 100, 100, 32) 0           activation_8[0][0]               
                                                                 batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 100, 100, 32) 0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 100, 100, 32) 9248        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 100, 100, 32) 128         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 100, 100, 32) 0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 100, 100, 32) 9248        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 100, 100, 32) 128         conv2d_13[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 100, 100, 32) 0           activation_10[0][0]              
                                                                 batch_normalization_12[0][0]     
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 100, 100, 32) 0           add_5[0][0]                      
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 50, 50, 64)   18496       activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 50, 50, 64)   256         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 50, 50, 64)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 50, 50, 64)   36928       activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 50, 50, 64)   2112        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 50, 50, 64)   256         conv2d_15[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 50, 50, 64)   0           conv2d_16[0][0]                  
                                                                 batch_normalization_14[0][0]     
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 50, 50, 64)   0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 50, 50, 64)   36928       activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 50, 50, 64)   256         conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 50, 50, 64)   0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 50, 50, 64)   36928       activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 50, 50, 64)   256         conv2d_18[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 50, 50, 64)   0           activation_14[0][0]              
                                                                 batch_normalization_16[0][0]     
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 50, 50, 64)   0           add_7[0][0]                      
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 50, 50, 64)   36928       activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 50, 50, 64)   256         conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 50, 50, 64)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 50, 50, 64)   36928       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 50, 50, 64)   256         conv2d_20[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 50, 50, 64)   0           activation_16[0][0]              
                                                                 batch_normalization_18[0][0]     
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 50, 50, 64)   0           add_8[0][0]                      
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 6, 6, 64)     0           activation_18[0][0]              
__________________________________________________________________________________________________
flatten (Flatten)               (None, 2304)         0           average_pooling2d[0][0]          
__________________________________________________________________________________________________
dense (Dense)                   (None, 1)            2305        flatten[0][0]                    
==================================================================================================
Total params: 275,809
Trainable params: 274,433
Non-trainable params: 1,376
__________________________________________________________________________________________________
Using the raw bias (no weights applied).
Using weights: {0: 1.0, 1: 1.0}
Train the ResNet using real-time data augmentation.
Learning rate:  0.001
Epoch 1/200
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.52857, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr1000_Te492_bs10_ep200_aug0_VIS1_NIR000_DBraw.h5
100/100 - 102s - loss: 0.9603 - tp: 243.0000 - fp: 236.0000 - tn: 264.0000 - fn: 257.0000 - acc: 0.5070 - auc: 0.5149 - val_loss: 0.8692 - val_tp: 182.0000 - val_fp: 168.0000 - val_tn: 77.0000 - val_fn: 63.0000 - val_acc: 0.5286 - val_auc: 0.5161
Learning rate:  0.001
Epoch 2/200
Epoch 1/200

Epoch 00002: val_acc did not improve from 0.52857
100/100 - 59s - loss: 0.8624 - tp: 272.0000 - fp: 250.0000 - tn: 250.0000 - fn: 228.0000 - acc: 0.5220 - auc: 0.5314 - val_loss: 0.8567 - val_tp: 75.0000 - val_fp: 72.0000 - val_tn: 173.0000 - val_fn: 170.0000 - val_acc: 0.5061 - val_auc: 0.5233
Learning rate:  0.001
Epoch 3/200
Epoch 1/200

Epoch 00003: val_acc did not improve from 0.52857
100/100 - 46s - loss: 0.8609 - tp: 270.0000 - fp: 257.0000 - tn: 243.0000 - fn: 230.0000 - acc: 0.5130 - auc: 0.5128 - val_loss: 0.8953 - val_tp: 216.0000 - val_fp: 211.0000 - val_tn: 34.0000 - val_fn: 29.0000 - val_acc: 0.5102 - val_auc: 0.4751
Learning rate:  0.001
Epoch 4/200
Epoch 1/200

Epoch 00004: val_acc did not improve from 0.52857
100/100 - 55s - loss: 0.8460 - tp: 253.0000 - fp: 227.0000 - tn: 273.0000 - fn: 247.0000 - acc: 0.5260 - auc: 0.5450 - val_loss: 0.8655 - val_tp: 185.0000 - val_fp: 178.0000 - val_tn: 67.0000 - val_fn: 60.0000 - val_acc: 0.5143 - val_auc: 0.4944
Learning rate:  0.001
Epoch 5/200
Epoch 1/200

Epoch 00005: val_acc did not improve from 0.52857
100/100 - 61s - loss: 0.8483 - tp: 268.0000 - fp: 237.0000 - tn: 263.0000 - fn: 232.0000 - acc: 0.5310 - auc: 0.5320 - val_loss: 0.8475 - val_tp: 59.0000 - val_fp: 78.0000 - val_tn: 167.0000 - val_fn: 186.0000 - val_acc: 0.4612 - val_auc: 0.4817
Learning rate:  0.001
Epoch 6/200
Epoch 1/200

Epoch 00006: val_acc did not improve from 0.52857
100/100 - 45s - loss: 0.8438 - tp: 253.0000 - fp: 232.0000 - tn: 268.0000 - fn: 247.0000 - acc: 0.5210 - auc: 0.5147 - val_loss: 0.8451 - val_tp: 133.0000 - val_fp: 147.0000 - val_tn: 98.0000 - val_fn: 112.0000 - val_acc: 0.4714 - val_auc: 0.4627
Learning rate:  0.001
Epoch 7/200
Epoch 1/200

Epoch 00007: val_acc did not improve from 0.52857
100/100 - 45s - loss: 0.8431 - tp: 256.0000 - fp: 249.0000 - tn: 251.0000 - fn: 244.0000 - acc: 0.5070 - auc: 0.5030 - val_loss: 0.8440 - val_tp: 180.0000 - val_fp: 174.0000 - val_tn: 71.0000 - val_fn: 65.0000 - val_acc: 0.5122 - val_auc: 0.5340
Learning rate:  0.001
Epoch 8/200
Epoch 1/200

Epoch 00008: val_acc did not improve from 0.52857
100/100 - 46s - loss: 0.8381 - tp: 236.0000 - fp: 232.0000 - tn: 268.0000 - fn: 264.0000 - acc: 0.5040 - auc: 0.5191 - val_loss: 0.8304 - val_tp: 148.0000 - val_fp: 148.0000 - val_tn: 97.0000 - val_fn: 97.0000 - val_acc: 0.5000 - val_auc: 0.5341
Learning rate:  0.001
Epoch 9/200
Epoch 1/200

Epoch 00009: val_acc did not improve from 0.52857
100/100 - 46s - loss: 0.8323 - tp: 267.0000 - fp: 264.0000 - tn: 236.0000 - fn: 233.0000 - acc: 0.5030 - auc: 0.5123 - val_loss: 0.8275 - val_tp: 93.0000 - val_fp: 94.0000 - val_tn: 151.0000 - val_fn: 152.0000 - val_acc: 0.4980 - val_auc: 0.5118
Learning rate:  0.001
Epoch 10/200
Epoch 1/200

Epoch 00010: val_acc did not improve from 0.52857
100/100 - 46s - loss: 0.8250 - tp: 253.0000 - fp: 249.0000 - tn: 251.0000 - fn: 247.0000 - acc: 0.5040 - auc: 0.5205 - val_loss: 0.8211 - val_tp: 212.0000 - val_fp: 205.0000 - val_tn: 40.0000 - val_fn: 33.0000 - val_acc: 0.5143 - val_auc: 0.5528
Learning rate:  0.001
Epoch 11/200
Epoch 1/200

Epoch 00011: val_acc did not improve from 0.52857
100/100 - 47s - loss: 0.8226 - tp: 256.0000 - fp: 254.0000 - tn: 246.0000 - fn: 244.0000 - acc: 0.5020 - auc: 0.5082 - val_loss: 0.8168 - val_tp: 188.0000 - val_fp: 179.0000 - val_tn: 66.0000 - val_fn: 57.0000 - val_acc: 0.5184 - val_auc: 0.5532
Learning rate:  0.001
Epoch 12/200
Epoch 1/200

Epoch 00012: val_acc improved from 0.52857 to 0.53265, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr1000_Te492_bs10_ep200_aug0_VIS1_NIR000_DBraw.h5
100/100 - 47s - loss: 0.8170 - tp: 270.0000 - fp: 260.0000 - tn: 240.0000 - fn: 230.0000 - acc: 0.5100 - auc: 0.5220 - val_loss: 0.8102 - val_tp: 174.0000 - val_fp: 158.0000 - val_tn: 87.0000 - val_fn: 71.0000 - val_acc: 0.5327 - val_auc: 0.5585
Learning rate:  0.001
Epoch 13/200
Epoch 1/200

Epoch 00013: val_acc did not improve from 0.53265
100/100 - 48s - loss: 0.8085 - tp: 243.0000 - fp: 202.0000 - tn: 298.0000 - fn: 257.0000 - acc: 0.5410 - auc: 0.5551 - val_loss: 0.8090 - val_tp: 160.0000 - val_fp: 153.0000 - val_tn: 92.0000 - val_fn: 85.0000 - val_acc: 0.5143 - val_auc: 0.5449
Learning rate:  0.001
Epoch 14/200
Epoch 1/200

Epoch 00014: val_acc improved from 0.53265 to 0.54694, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr1000_Te492_bs10_ep200_aug0_VIS1_NIR000_DBraw.h5
100/100 - 48s - loss: 0.8022 - tp: 253.0000 - fp: 213.0000 - tn: 287.0000 - fn: 247.0000 - acc: 0.5400 - auc: 0.5731 - val_loss: 0.8447 - val_tp: 184.0000 - val_fp: 161.0000 - val_tn: 84.0000 - val_fn: 61.0000 - val_acc: 0.5469 - val_auc: 0.5911
Learning rate:  0.001
Epoch 15/200
Epoch 1/200

Epoch 00015: val_acc did not improve from 0.54694
100/100 - 48s - loss: 0.8030 - tp: 232.0000 - fp: 207.0000 - tn: 293.0000 - fn: 268.0000 - acc: 0.5250 - auc: 0.5447 - val_loss: 0.8084 - val_tp: 141.0000 - val_fp: 122.0000 - val_tn: 123.0000 - val_fn: 104.0000 - val_acc: 0.5388 - val_auc: 0.5375
Learning rate:  0.001
Epoch 16/200
Epoch 1/200

Epoch 00016: val_acc did not improve from 0.54694
100/100 - 48s - loss: 0.8043 - tp: 243.0000 - fp: 218.0000 - tn: 282.0000 - fn: 257.0000 - acc: 0.5250 - auc: 0.5251 - val_loss: 0.7993 - val_tp: 124.0000 - val_fp: 126.0000 - val_tn: 119.0000 - val_fn: 121.0000 - val_acc: 0.4959 - val_auc: 0.5213
Learning rate:  0.001
Epoch 17/200
Epoch 1/200

Epoch 00017: val_acc did not improve from 0.54694
100/100 - 49s - loss: 0.7966 - tp: 267.0000 - fp: 209.0000 - tn: 291.0000 - fn: 233.0000 - acc: 0.5580 - auc: 0.5495 - val_loss: 0.7944 - val_tp: 88.0000 - val_fp: 74.0000 - val_tn: 171.0000 - val_fn: 157.0000 - val_acc: 0.5286 - val_auc: 0.5562
Learning rate:  0.001
Epoch 18/200
Epoch 1/200

Epoch 00018: val_acc did not improve from 0.54694
100/100 - 50s - loss: 0.7932 - tp: 284.0000 - fp: 240.0000 - tn: 260.0000 - fn: 216.0000 - acc: 0.5440 - auc: 0.5590 - val_loss: 0.7935 - val_tp: 213.0000 - val_fp: 215.0000 - val_tn: 30.0000 - val_fn: 32.0000 - val_acc: 0.4959 - val_auc: 0.5494
Learning rate:  0.001
Epoch 19/200
Epoch 1/200

Epoch 00019: val_acc did not improve from 0.54694
100/100 - 57s - loss: 0.7897 - tp: 226.0000 - fp: 207.0000 - tn: 293.0000 - fn: 274.0000 - acc: 0.5190 - auc: 0.5308 - val_loss: 0.7867 - val_tp: 42.0000 - val_fp: 24.0000 - val_tn: 221.0000 - val_fn: 203.0000 - val_acc: 0.5367 - val_auc: 0.5753
Epoch 1/200
Learning rate:  0.001
Epoch 20/200
Epoch 1/200

Epoch 00020: val_acc did not improve from 0.54694
100/100 - 69s - loss: 0.7745 - tp: 256.0000 - fp: 193.0000 - tn: 307.0000 - fn: 244.0000 - acc: 0.5630 - auc: 0.5831 - val_loss: 0.7843 - val_tp: 124.0000 - val_fp: 112.0000 - val_tn: 133.0000 - val_fn: 121.0000 - val_acc: 0.5245 - val_auc: 0.5532
Learning rate:  0.001
Epoch 21/200
Epoch 1/200

Epoch 00021: val_acc improved from 0.54694 to 0.56735, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr1000_Te492_bs10_ep200_aug0_VIS1_NIR000_DBraw.h5
100/100 - 52s - loss: 0.7844 - tp: 272.0000 - fp: 225.0000 - tn: 275.0000 - fn: 228.0000 - acc: 0.5470 - auc: 0.5548 - val_loss: 0.7720 - val_tp: 96.0000 - val_fp: 63.0000 - val_tn: 182.0000 - val_fn: 149.0000 - val_acc: 0.5673 - val_auc: 0.6025
Learning rate:  0.001
Epoch 22/200
Epoch 1/200

Epoch 00022: val_acc did not improve from 0.56735
100/100 - 55s - loss: 0.7728 - tp: 272.0000 - fp: 209.0000 - tn: 291.0000 - fn: 228.0000 - acc: 0.5630 - auc: 0.5891 - val_loss: 0.7850 - val_tp: 139.0000 - val_fp: 137.0000 - val_tn: 108.0000 - val_fn: 106.0000 - val_acc: 0.5041 - val_auc: 0.5146
Learning rate:  0.001
Epoch 23/200
Epoch 1/200

Epoch 00023: val_acc did not improve from 0.56735
100/100 - 76s - loss: 0.7753 - tp: 251.0000 - fp: 208.0000 - tn: 292.0000 - fn: 249.0000 - acc: 0.5430 - auc: 0.5614 - val_loss: 0.7671 - val_tp: 129.0000 - val_fp: 97.0000 - val_tn: 148.0000 - val_fn: 116.0000 - val_acc: 0.5653 - val_auc: 0.5801
Learning rate:  0.001
Epoch 24/200
Epoch 1/200

Epoch 00024: val_acc did not improve from 0.56735
100/100 - 51s - loss: 0.7633 - tp: 254.0000 - fp: 188.0000 - tn: 312.0000 - fn: 246.0000 - acc: 0.5660 - auc: 0.5874 - val_loss: 0.7687 - val_tp: 145.0000 - val_fp: 123.0000 - val_tn: 122.0000 - val_fn: 100.0000 - val_acc: 0.5449 - val_auc: 0.5748
Learning rate:  0.001
Epoch 25/200
Epoch 1/200

Epoch 00025: val_acc did not improve from 0.56735
100/100 - 52s - loss: 0.7688 - tp: 241.0000 - fp: 215.0000 - tn: 285.0000 - fn: 259.0000 - acc: 0.5260 - auc: 0.5432 - val_loss: 0.7571 - val_tp: 136.0000 - val_fp: 114.0000 - val_tn: 131.0000 - val_fn: 109.0000 - val_acc: 0.5449 - val_auc: 0.5875
Learning rate:  0.001
Epoch 26/200
Epoch 1/200

Epoch 00026: val_acc did not improve from 0.56735
100/100 - 53s - loss: 0.7572 - tp: 246.0000 - fp: 198.0000 - tn: 302.0000 - fn: 254.0000 - acc: 0.5480 - auc: 0.5855 - val_loss: 0.7659 - val_tp: 118.0000 - val_fp: 97.0000 - val_tn: 148.0000 - val_fn: 127.0000 - val_acc: 0.5429 - val_auc: 0.5695
Learning rate:  0.001
Epoch 27/200
Epoch 1/200

Epoch 00027: val_acc did not improve from 0.56735
100/100 - 54s - loss: 0.7576 - tp: 248.0000 - fp: 189.0000 - tn: 311.0000 - fn: 252.0000 - acc: 0.5590 - auc: 0.5852 - val_loss: 0.7585 - val_tp: 45.0000 - val_fp: 24.0000 - val_tn: 221.0000 - val_fn: 200.0000 - val_acc: 0.5429 - val_auc: 0.5888
Learning rate:  0.001
Epoch 28/200
Epoch 1/200

Epoch 00028: val_acc did not improve from 0.56735
100/100 - 54s - loss: 0.7469 - tp: 241.0000 - fp: 166.0000 - tn: 334.0000 - fn: 259.0000 - acc: 0.5750 - auc: 0.5962 - val_loss: 0.7587 - val_tp: 100.0000 - val_fp: 87.0000 - val_tn: 158.0000 - val_fn: 145.0000 - val_acc: 0.5265 - val_auc: 0.5374
Learning rate:  0.001
Epoch 29/200
Epoch 1/200

Epoch 00029: val_acc did not improve from 0.56735
100/100 - 55s - loss: 0.7475 - tp: 270.0000 - fp: 183.0000 - tn: 317.0000 - fn: 230.0000 - acc: 0.5870 - auc: 0.6076 - val_loss: 0.7584 - val_tp: 28.0000 - val_fp: 11.0000 - val_tn: 234.0000 - val_fn: 217.0000 - val_acc: 0.5347 - val_auc: 0.5680
Learning rate:  0.001
Epoch 30/200
Epoch 1/200

Epoch 00030: val_acc did not improve from 0.56735
100/100 - 55s - loss: 0.7387 - tp: 270.0000 - fp: 175.0000 - tn: 325.0000 - fn: 230.0000 - acc: 0.5950 - auc: 0.6260 - val_loss: 0.7534 - val_tp: 142.0000 - val_fp: 126.0000 - val_tn: 119.0000 - val_fn: 103.0000 - val_acc: 0.5327 - val_auc: 0.5650
Learning rate:  0.001
Epoch 31/200
Epoch 1/200

Epoch 00031: val_acc did not improve from 0.56735
100/100 - 56s - loss: 0.7433 - tp: 274.0000 - fp: 198.0000 - tn: 302.0000 - fn: 226.0000 - acc: 0.5760 - auc: 0.6037 - val_loss: 0.7472 - val_tp: 146.0000 - val_fp: 123.0000 - val_tn: 122.0000 - val_fn: 99.0000 - val_acc: 0.5469 - val_auc: 0.5710
Learning rate:  0.001
Epoch 32/200
Epoch 1/200

Epoch 00032: val_acc improved from 0.56735 to 0.57143, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr1000_Te492_bs10_ep200_aug0_VIS1_NIR000_DBraw.h5
100/100 - 56s - loss: 0.7423 - tp: 232.0000 - fp: 189.0000 - tn: 311.0000 - fn: 268.0000 - acc: 0.5430 - auc: 0.5881 - val_loss: 0.7424 - val_tp: 71.0000 - val_fp: 36.0000 - val_tn: 209.0000 - val_fn: 174.0000 - val_acc: 0.5714 - val_auc: 0.5912
Learning rate:  0.001
Epoch 33/200
Epoch 1/200

Epoch 00033: val_acc did not improve from 0.57143
100/100 - 56s - loss: 0.7413 - tp: 261.0000 - fp: 185.0000 - tn: 315.0000 - fn: 239.0000 - acc: 0.5760 - auc: 0.5986 - val_loss: 0.7359 - val_tp: 124.0000 - val_fp: 94.0000 - val_tn: 151.0000 - val_fn: 121.0000 - val_acc: 0.5612 - val_auc: 0.6027
Learning rate:  0.001
Epoch 34/200
Epoch 1/200

Epoch 00034: val_acc did not improve from 0.57143
100/100 - 56s - loss: 0.7340 - tp: 264.0000 - fp: 183.0000 - tn: 317.0000 - fn: 236.0000 - acc: 0.5810 - auc: 0.6078 - val_loss: 0.7386 - val_tp: 64.0000 - val_fp: 31.0000 - val_tn: 214.0000 - val_fn: 181.0000 - val_acc: 0.5673 - val_auc: 0.5997
Epoch 1/200
Learning rate:  0.001
Epoch 35/200
Epoch 1/200

Epoch 00035: val_acc did not improve from 0.57143
100/100 - 66s - loss: 0.7294 - tp: 262.0000 - fp: 190.0000 - tn: 310.0000 - fn: 238.0000 - acc: 0.5720 - auc: 0.6034 - val_loss: 0.7380 - val_tp: 64.0000 - val_fp: 44.0000 - val_tn: 201.0000 - val_fn: 181.0000 - val_acc: 0.5408 - val_auc: 0.5763
Learning rate:  0.001
Epoch 36/200
Epoch 1/200

Epoch 00036: val_acc did not improve from 0.57143
100/100 - 63s - loss: 0.7287 - tp: 236.0000 - fp: 161.0000 - tn: 339.0000 - fn: 264.0000 - acc: 0.5750 - auc: 0.6040 - val_loss: 0.7298 - val_tp: 77.0000 - val_fp: 43.0000 - val_tn: 202.0000 - val_fn: 168.0000 - val_acc: 0.5694 - val_auc: 0.6004
Learning rate:  0.001
Epoch 37/200
Epoch 1/200

Epoch 00037: val_acc did not improve from 0.57143
100/100 - 64s - loss: 0.7231 - tp: 254.0000 - fp: 157.0000 - tn: 343.0000 - fn: 246.0000 - acc: 0.5970 - auc: 0.6232 - val_loss: 0.7343 - val_tp: 80.0000 - val_fp: 46.0000 - val_tn: 199.0000 - val_fn: 165.0000 - val_acc: 0.5694 - val_auc: 0.5795
Epoch 1/200
Learning rate:  0.001
Epoch 38/200
Epoch 1/200

Epoch 00038: val_acc did not improve from 0.57143
100/100 - 69s - loss: 0.7378 - tp: 221.0000 - fp: 160.0000 - tn: 340.0000 - fn: 279.0000 - acc: 0.5610 - auc: 0.5942 - val_loss: 0.7311 - val_tp: 57.0000 - val_fp: 29.0000 - val_tn: 216.0000 - val_fn: 188.0000 - val_acc: 0.5571 - val_auc: 0.6068
Learning rate:  0.001
Epoch 39/200
Epoch 1/200

Epoch 00039: val_acc did not improve from 0.57143
100/100 - 67s - loss: 0.7227 - tp: 261.0000 - fp: 188.0000 - tn: 312.0000 - fn: 239.0000 - acc: 0.5730 - auc: 0.6185 - val_loss: 0.7380 - val_tp: 132.0000 - val_fp: 113.0000 - val_tn: 132.0000 - val_fn: 113.0000 - val_acc: 0.5388 - val_auc: 0.5708
Learning rate:  0.001
Epoch 40/200
Epoch 1/200

Epoch 00040: val_acc did not improve from 0.57143
100/100 - 59s - loss: 0.7212 - tp: 255.0000 - fp: 171.0000 - tn: 329.0000 - fn: 245.0000 - acc: 0.5840 - auc: 0.6037 - val_loss: 0.7295 - val_tp: 53.0000 - val_fp: 24.0000 - val_tn: 221.0000 - val_fn: 192.0000 - val_acc: 0.5592 - val_auc: 0.5967
Learning rate:  0.001
Epoch 41/200
Epoch 1/200

Epoch 00041: val_acc did not improve from 0.57143
100/100 - 68s - loss: 0.7323 - tp: 231.0000 - fp: 176.0000 - tn: 324.0000 - fn: 269.0000 - acc: 0.5550 - auc: 0.5857 - val_loss: 0.7275 - val_tp: 95.0000 - val_fp: 61.0000 - val_tn: 184.0000 - val_fn: 150.0000 - val_acc: 0.5694 - val_auc: 0.5833
Learning rate:  0.001
Epoch 42/200
Epoch 1/200

Epoch 00042: val_acc did not improve from 0.57143
100/100 - 61s - loss: 0.7254 - tp: 244.0000 - fp: 183.0000 - tn: 317.0000 - fn: 256.0000 - acc: 0.5610 - auc: 0.5914 - val_loss: 0.7215 - val_tp: 111.0000 - val_fp: 78.0000 - val_tn: 167.0000 - val_fn: 134.0000 - val_acc: 0.5673 - val_auc: 0.6139
Learning rate:  0.001
Epoch 43/200
Epoch 1/200

Epoch 00043: val_acc did not improve from 0.57143
100/100 - 61s - loss: 0.7213 - tp: 238.0000 - fp: 173.0000 - tn: 327.0000 - fn: 262.0000 - acc: 0.5650 - auc: 0.6014 - val_loss: 0.7300 - val_tp: 169.0000 - val_fp: 141.0000 - val_tn: 104.0000 - val_fn: 76.0000 - val_acc: 0.5571 - val_auc: 0.5868
Learning rate:  0.001
Epoch 44/200
Epoch 1/200

Epoch 00044: val_acc did not improve from 0.57143
100/100 - 62s - loss: 0.7137 - tp: 271.0000 - fp: 171.0000 - tn: 329.0000 - fn: 229.0000 - acc: 0.6000 - auc: 0.6148 - val_loss: 0.7307 - val_tp: 158.0000 - val_fp: 140.0000 - val_tn: 105.0000 - val_fn: 87.0000 - val_acc: 0.5367 - val_auc: 0.5855
Learning rate:  0.001
Epoch 45/200
Epoch 1/200

Epoch 00045: val_acc did not improve from 0.57143
100/100 - 61s - loss: 0.7041 - tp: 252.0000 - fp: 149.0000 - tn: 351.0000 - fn: 248.0000 - acc: 0.6030 - auc: 0.6310 - val_loss: 0.7470 - val_tp: 62.0000 - val_fp: 44.0000 - val_tn: 201.0000 - val_fn: 183.0000 - val_acc: 0.5367 - val_auc: 0.5242
Learning rate:  0.001
Epoch 46/200
Epoch 1/200

Epoch 00046: val_acc did not improve from 0.57143
100/100 - 62s - loss: 0.7150 - tp: 218.0000 - fp: 142.0000 - tn: 358.0000 - fn: 282.0000 - acc: 0.5760 - auc: 0.6082 - val_loss: 0.7263 - val_tp: 71.0000 - val_fp: 51.0000 - val_tn: 194.0000 - val_fn: 174.0000 - val_acc: 0.5408 - val_auc: 0.5686
Learning rate:  0.001
Epoch 47/200
Epoch 1/200

Epoch 00047: val_acc did not improve from 0.57143
100/100 - 63s - loss: 0.7106 - tp: 262.0000 - fp: 162.0000 - tn: 338.0000 - fn: 238.0000 - acc: 0.6000 - auc: 0.6262 - val_loss: 0.7580 - val_tp: 145.0000 - val_fp: 132.0000 - val_tn: 113.0000 - val_fn: 100.0000 - val_acc: 0.5265 - val_auc: 0.5509
Learning rate:  0.001
Epoch 48/200
Epoch 1/200

Epoch 00048: val_acc did not improve from 0.57143
100/100 - 64s - loss: 0.7089 - tp: 225.0000 - fp: 145.0000 - tn: 355.0000 - fn: 275.0000 - acc: 0.5800 - auc: 0.6167 - val_loss: 0.7282 - val_tp: 27.0000 - val_fp: 11.0000 - val_tn: 234.0000 - val_fn: 218.0000 - val_acc: 0.5327 - val_auc: 0.5856
Learning rate:  0.001
Epoch 49/200
Epoch 1/200

Epoch 00049: val_acc did not improve from 0.57143
100/100 - 65s - loss: 0.7038 - tp: 242.0000 - fp: 161.0000 - tn: 339.0000 - fn: 258.0000 - acc: 0.5810 - auc: 0.6231 - val_loss: 0.7184 - val_tp: 85.0000 - val_fp: 55.0000 - val_tn: 190.0000 - val_fn: 160.0000 - val_acc: 0.5612 - val_auc: 0.5882
Learning rate:  0.001
Epoch 50/200
Epoch 1/200

Epoch 00050: val_acc did not improve from 0.57143
100/100 - 76s - loss: 0.7120 - tp: 260.0000 - fp: 168.0000 - tn: 332.0000 - fn: 240.0000 - acc: 0.5920 - auc: 0.6151 - val_loss: 0.8514 - val_tp: 173.0000 - val_fp: 174.0000 - val_tn: 71.0000 - val_fn: 72.0000 - val_acc: 0.4980 - val_auc: 0.5696
Learning rate:  0.001
Epoch 51/200
Epoch 1/200

Epoch 00051: val_acc improved from 0.57143 to 0.57755, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr1000_Te492_bs10_ep200_aug0_VIS1_NIR000_DBraw.h5
100/100 - 84s - loss: 0.6939 - tp: 247.0000 - fp: 148.0000 - tn: 352.0000 - fn: 253.0000 - acc: 0.5990 - auc: 0.6446 - val_loss: 0.7104 - val_tp: 68.0000 - val_fp: 30.0000 - val_tn: 215.0000 - val_fn: 177.0000 - val_acc: 0.5776 - val_auc: 0.6101
Epoch 1/200
Learning rate:  0.001
Epoch 52/200
Epoch 1/200

Epoch 00052: val_acc did not improve from 0.57755
100/100 - 75s - loss: 0.7019 - tp: 239.0000 - fp: 136.0000 - tn: 364.0000 - fn: 261.0000 - acc: 0.6030 - auc: 0.6316 - val_loss: 0.7265 - val_tp: 32.0000 - val_fp: 13.0000 - val_tn: 232.0000 - val_fn: 213.0000 - val_acc: 0.5388 - val_auc: 0.6142
Learning rate:  0.001
Epoch 53/200
Epoch 1/200

Epoch 00053: val_acc did not improve from 0.57755
100/100 - 73s - loss: 0.7097 - tp: 219.0000 - fp: 151.0000 - tn: 349.0000 - fn: 281.0000 - acc: 0.5680 - auc: 0.6021 - val_loss: 0.7128 - val_tp: 88.0000 - val_fp: 56.0000 - val_tn: 189.0000 - val_fn: 157.0000 - val_acc: 0.5653 - val_auc: 0.5848
Learning rate:  0.001
Epoch 54/200
Epoch 1/200

Epoch 00054: val_acc did not improve from 0.57755
100/100 - 68s - loss: 0.7004 - tp: 235.0000 - fp: 135.0000 - tn: 365.0000 - fn: 265.0000 - acc: 0.6000 - auc: 0.6284 - val_loss: 0.7218 - val_tp: 54.0000 - val_fp: 24.0000 - val_tn: 221.0000 - val_fn: 191.0000 - val_acc: 0.5612 - val_auc: 0.5882
Learning rate:  0.001
Epoch 55/200
Epoch 1/200

Epoch 00055: val_acc did not improve from 0.57755
100/100 - 76s - loss: 0.7073 - tp: 213.0000 - fp: 131.0000 - tn: 369.0000 - fn: 287.0000 - acc: 0.5820 - auc: 0.5894 - val_loss: 0.7140 - val_tp: 82.0000 - val_fp: 48.0000 - val_tn: 197.0000 - val_fn: 163.0000 - val_acc: 0.5694 - val_auc: 0.5881
Learning rate:  0.001
Epoch 56/200
Epoch 1/200

Epoch 00056: val_acc did not improve from 0.57755
100/100 - 68s - loss: 0.7011 - tp: 249.0000 - fp: 153.0000 - tn: 347.0000 - fn: 251.0000 - acc: 0.5960 - auc: 0.6316 - val_loss: 0.7122 - val_tp: 40.0000 - val_fp: 14.0000 - val_tn: 231.0000 - val_fn: 205.0000 - val_acc: 0.5531 - val_auc: 0.6082
Learning rate:  0.001
Epoch 57/200
Epoch 1/200

Epoch 00057: val_acc did not improve from 0.57755
100/100 - 68s - loss: 0.6990 - tp: 211.0000 - fp: 127.0000 - tn: 373.0000 - fn: 289.0000 - acc: 0.5840 - auc: 0.6211 - val_loss: 0.7022 - val_tp: 120.0000 - val_fp: 91.0000 - val_tn: 154.0000 - val_fn: 125.0000 - val_acc: 0.5592 - val_auc: 0.6080
Learning rate:  0.001
Epoch 58/200
Epoch 1/200

Epoch 00058: val_acc did not improve from 0.57755
100/100 - 68s - loss: 0.6840 - tp: 252.0000 - fp: 141.0000 - tn: 359.0000 - fn: 248.0000 - acc: 0.6110 - auc: 0.6463 - val_loss: 0.7444 - val_tp: 153.0000 - val_fp: 132.0000 - val_tn: 113.0000 - val_fn: 92.0000 - val_acc: 0.5429 - val_auc: 0.5786
Learning rate:  0.001
Epoch 59/200
Epoch 1/200

Epoch 00059: val_acc did not improve from 0.57755
100/100 - 70s - loss: 0.6984 - tp: 241.0000 - fp: 145.0000 - tn: 355.0000 - fn: 259.0000 - acc: 0.5960 - auc: 0.6295 - val_loss: 0.7225 - val_tp: 146.0000 - val_fp: 130.0000 - val_tn: 115.0000 - val_fn: 99.0000 - val_acc: 0.5327 - val_auc: 0.5737
Learning rate:  0.001
Epoch 60/200
Epoch 1/200

Epoch 00060: val_acc did not improve from 0.57755
100/100 - 69s - loss: 0.6894 - tp: 230.0000 - fp: 133.0000 - tn: 367.0000 - fn: 270.0000 - acc: 0.5970 - auc: 0.6423 - val_loss: 0.7102 - val_tp: 76.0000 - val_fp: 53.0000 - val_tn: 192.0000 - val_fn: 169.0000 - val_acc: 0.5469 - val_auc: 0.5781
Learning rate:  0.001
Epoch 61/200
Epoch 1/200

Epoch 00061: val_acc did not improve from 0.57755
100/100 - 70s - loss: 0.6857 - tp: 235.0000 - fp: 131.0000 - tn: 369.0000 - fn: 265.0000 - acc: 0.6040 - auc: 0.6422 - val_loss: 0.7055 - val_tp: 93.0000 - val_fp: 59.0000 - val_tn: 186.0000 - val_fn: 152.0000 - val_acc: 0.5694 - val_auc: 0.5948
Learning rate:  0.001
Epoch 62/200
Epoch 1/200

Epoch 00062: val_acc did not improve from 0.57755
100/100 - 73s - loss: 0.6911 - tp: 261.0000 - fp: 146.0000 - tn: 354.0000 - fn: 239.0000 - acc: 0.6150 - auc: 0.6487 - val_loss: 0.7228 - val_tp: 57.0000 - val_fp: 24.0000 - val_tn: 221.0000 - val_fn: 188.0000 - val_acc: 0.5673 - val_auc: 0.5736
Learning rate:  0.001
Epoch 63/200
Epoch 1/200

Epoch 00063: val_acc did not improve from 0.57755
100/100 - 82s - loss: 0.7059 - tp: 260.0000 - fp: 172.0000 - tn: 328.0000 - fn: 240.0000 - acc: 0.5880 - auc: 0.6245 - val_loss: 0.7229 - val_tp: 118.0000 - val_fp: 89.0000 - val_tn: 156.0000 - val_fn: 127.0000 - val_acc: 0.5592 - val_auc: 0.5842
Learning rate:  0.001
Epoch 64/200
Epoch 1/200

Epoch 00064: val_acc did not improve from 0.57755
100/100 - 92s - loss: 0.6838 - tp: 263.0000 - fp: 151.0000 - tn: 349.0000 - fn: 237.0000 - acc: 0.6120 - auc: 0.6558 - val_loss: 1.4208 - val_tp: 191.0000 - val_fp: 182.0000 - val_tn: 63.0000 - val_fn: 54.0000 - val_acc: 0.5184 - val_auc: 0.5381
Learning rate:  0.001
Epoch 65/200
Epoch 1/200

Epoch 00065: val_acc did not improve from 0.57755
100/100 - 77s - loss: 0.6944 - tp: 236.0000 - fp: 147.0000 - tn: 353.0000 - fn: 264.0000 - acc: 0.5890 - auc: 0.6207 - val_loss: 0.7270 - val_tp: 24.0000 - val_fp: 14.0000 - val_tn: 231.0000 - val_fn: 221.0000 - val_acc: 0.5204 - val_auc: 0.5781
Epoch 1/200
Learning rate:  0.001
Epoch 66/200
Epoch 1/200

Epoch 00066: val_acc did not improve from 0.57755
100/100 - 76s - loss: 0.6888 - tp: 241.0000 - fp: 151.0000 - tn: 349.0000 - fn: 259.0000 - acc: 0.5900 - auc: 0.6412 - val_loss: 0.7000 - val_tp: 97.0000 - val_fp: 68.0000 - val_tn: 177.0000 - val_fn: 148.0000 - val_acc: 0.5592 - val_auc: 0.5957
Learning rate:  0.001
Epoch 67/200
Epoch 1/200

Epoch 00067: val_acc did not improve from 0.57755
100/100 - 75s - loss: 0.6816 - tp: 250.0000 - fp: 130.0000 - tn: 370.0000 - fn: 250.0000 - acc: 0.6200 - auc: 0.6526 - val_loss: 0.7077 - val_tp: 50.0000 - val_fp: 13.0000 - val_tn: 232.0000 - val_fn: 195.0000 - val_acc: 0.5755 - val_auc: 0.6012
Learning rate:  0.001
Epoch 68/200
Epoch 1/200

Epoch 00068: val_acc did not improve from 0.57755
100/100 - 74s - loss: 0.6818 - tp: 258.0000 - fp: 126.0000 - tn: 374.0000 - fn: 242.0000 - acc: 0.6320 - auc: 0.6730 - val_loss: 0.7432 - val_tp: 136.0000 - val_fp: 123.0000 - val_tn: 122.0000 - val_fn: 109.0000 - val_acc: 0.5265 - val_auc: 0.5616
Learning rate:  0.001
Epoch 69/200
Epoch 1/200

Epoch 00069: val_acc did not improve from 0.57755
100/100 - 76s - loss: 0.6739 - tp: 279.0000 - fp: 135.0000 - tn: 365.0000 - fn: 221.0000 - acc: 0.6440 - auc: 0.6838 - val_loss: 0.7188 - val_tp: 48.0000 - val_fp: 19.0000 - val_tn: 226.0000 - val_fn: 197.0000 - val_acc: 0.5592 - val_auc: 0.5788
Learning rate:  0.001
Epoch 70/200
Epoch 1/200

Epoch 00070: val_acc did not improve from 0.57755
100/100 - 75s - loss: 0.6666 - tp: 260.0000 - fp: 129.0000 - tn: 371.0000 - fn: 240.0000 - acc: 0.6310 - auc: 0.6694 - val_loss: 0.7079 - val_tp: 116.0000 - val_fp: 91.0000 - val_tn: 154.0000 - val_fn: 129.0000 - val_acc: 0.5510 - val_auc: 0.6020
Epoch 1/200
Learning rate:  0.001
Epoch 71/200
Epoch 1/200

Epoch 00071: val_acc did not improve from 0.57755
100/100 - 83s - loss: 0.6885 - tp: 246.0000 - fp: 137.0000 - tn: 363.0000 - fn: 254.0000 - acc: 0.6090 - auc: 0.6588 - val_loss: 0.7077 - val_tp: 80.0000 - val_fp: 57.0000 - val_tn: 188.0000 - val_fn: 165.0000 - val_acc: 0.5469 - val_auc: 0.5726
Learning rate:  0.001
Epoch 72/200
Epoch 1/200

Epoch 00072: val_acc did not improve from 0.57755
100/100 - 76s - loss: 0.6924 - tp: 256.0000 - fp: 169.0000 - tn: 331.0000 - fn: 244.0000 - acc: 0.5870 - auc: 0.6307 - val_loss: 0.7071 - val_tp: 49.0000 - val_fp: 19.0000 - val_tn: 226.0000 - val_fn: 196.0000 - val_acc: 0.5612 - val_auc: 0.6349
Learning rate:  0.001
Epoch 73/200
Epoch 1/200

Epoch 00073: val_acc did not improve from 0.57755
100/100 - 76s - loss: 0.6672 - tp: 257.0000 - fp: 124.0000 - tn: 376.0000 - fn: 243.0000 - acc: 0.6330 - auc: 0.6771 - val_loss: 0.7228 - val_tp: 152.0000 - val_fp: 127.0000 - val_tn: 118.0000 - val_fn: 93.0000 - val_acc: 0.5510 - val_auc: 0.5855
Learning rate:  0.001
Epoch 74/200
Epoch 1/200

Epoch 00074: val_acc did not improve from 0.57755
100/100 - 78s - loss: 0.6815 - tp: 267.0000 - fp: 143.0000 - tn: 357.0000 - fn: 233.0000 - acc: 0.6240 - auc: 0.6607 - val_loss: 0.7292 - val_tp: 45.0000 - val_fp: 10.0000 - val_tn: 235.0000 - val_fn: 200.0000 - val_acc: 0.5714 - val_auc: 0.6011
Epoch 1/200
Learning rate:  0.001
Epoch 75/200
Epoch 1/200

Epoch 00075: val_acc improved from 0.57755 to 0.58367, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr1000_Te492_bs10_ep200_aug0_VIS1_NIR000_DBraw.h5
100/100 - 93s - loss: 0.6507 - tp: 275.0000 - fp: 126.0000 - tn: 374.0000 - fn: 225.0000 - acc: 0.6490 - auc: 0.7050 - val_loss: 0.7015 - val_tp: 80.0000 - val_fp: 39.0000 - val_tn: 206.0000 - val_fn: 165.0000 - val_acc: 0.5837 - val_auc: 0.6176
Epoch 1/200
Learning rate:  0.001
Epoch 76/200
Epoch 1/200

Epoch 00076: val_acc improved from 0.58367 to 0.58776, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr1000_Te492_bs10_ep200_aug0_VIS1_NIR000_DBraw.h5
100/100 - 79s - loss: 0.6659 - tp: 247.0000 - fp: 128.0000 - tn: 372.0000 - fn: 253.0000 - acc: 0.6190 - auc: 0.6789 - val_loss: 0.6873 - val_tp: 92.0000 - val_fp: 49.0000 - val_tn: 196.0000 - val_fn: 153.0000 - val_acc: 0.5878 - val_auc: 0.6386
Learning rate:  0.001
Epoch 77/200
Epoch 1/200

Epoch 00077: val_acc did not improve from 0.58776
100/100 - 98s - loss: 0.6605 - tp: 274.0000 - fp: 128.0000 - tn: 372.0000 - fn: 226.0000 - acc: 0.6460 - auc: 0.6950 - val_loss: 0.7056 - val_tp: 96.0000 - val_fp: 71.0000 - val_tn: 174.0000 - val_fn: 149.0000 - val_acc: 0.5510 - val_auc: 0.5776
Learning rate:  0.001
Epoch 78/200
Epoch 1/200

Epoch 00078: val_acc did not improve from 0.58776
100/100 - 81s - loss: 0.6675 - tp: 260.0000 - fp: 140.0000 - tn: 360.0000 - fn: 240.0000 - acc: 0.6200 - auc: 0.6715 - val_loss: 0.8350 - val_tp: 179.0000 - val_fp: 182.0000 - val_tn: 63.0000 - val_fn: 66.0000 - val_acc: 0.4939 - val_auc: 0.5635
Learning rate:  0.001
Epoch 79/200
Epoch 1/200

Epoch 00079: val_acc did not improve from 0.58776
100/100 - 84s - loss: 0.6768 - tp: 236.0000 - fp: 122.0000 - tn: 378.0000 - fn: 264.0000 - acc: 0.6140 - auc: 0.6618 - val_loss: 0.6974 - val_tp: 79.0000 - val_fp: 37.0000 - val_tn: 208.0000 - val_fn: 166.0000 - val_acc: 0.5857 - val_auc: 0.6314
Epoch 1/200
Learning rate:  0.001
Epoch 80/200
Epoch 1/200

Epoch 00080: val_acc improved from 0.58776 to 0.59388, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr1000_Te492_bs10_ep200_aug0_VIS1_NIR000_DBraw.h5
100/100 - 82s - loss: 0.6778 - tp: 267.0000 - fp: 144.0000 - tn: 356.0000 - fn: 233.0000 - acc: 0.6230 - auc: 0.6598 - val_loss: 0.6902 - val_tp: 97.0000 - val_fp: 51.0000 - val_tn: 194.0000 - val_fn: 148.0000 - val_acc: 0.5939 - val_auc: 0.6125
Learning rate:  0.001
Epoch 81/200
Epoch 1/200

Epoch 00081: val_acc did not improve from 0.59388
100/100 - 84s - loss: 0.6821 - tp: 271.0000 - fp: 150.0000 - tn: 350.0000 - fn: 229.0000 - acc: 0.6210 - auc: 0.6642 - val_loss: 0.7160 - val_tp: 55.0000 - val_fp: 13.0000 - val_tn: 232.0000 - val_fn: 190.0000 - val_acc: 0.5857 - val_auc: 0.6263
Epoch 1/200
Learning rate:  0.0001
Epoch 82/200
Epoch 1/200

Epoch 00082: val_acc did not improve from 0.59388
100/100 - 83s - loss: 0.6666 - tp: 240.0000 - fp: 102.0000 - tn: 398.0000 - fn: 260.0000 - acc: 0.6380 - auc: 0.6852 - val_loss: 0.6813 - val_tp: 81.0000 - val_fp: 36.0000 - val_tn: 209.0000 - val_fn: 164.0000 - val_acc: 0.5918 - val_auc: 0.6446
Learning rate:  0.0001
Epoch 83/200
Epoch 1/200

Epoch 00083: val_acc improved from 0.59388 to 0.59592, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr1000_Te492_bs10_ep200_aug0_VIS1_NIR000_DBraw.h5
100/100 - 86s - loss: 0.6573 - tp: 250.0000 - fp: 106.0000 - tn: 394.0000 - fn: 250.0000 - acc: 0.6440 - auc: 0.6923 - val_loss: 0.6793 - val_tp: 91.0000 - val_fp: 44.0000 - val_tn: 201.0000 - val_fn: 154.0000 - val_acc: 0.5959 - val_auc: 0.6351
Learning rate:  0.0001
Epoch 84/200
Epoch 1/200

Epoch 00084: val_acc improved from 0.59592 to 0.60204, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr1000_Te492_bs10_ep200_aug0_VIS1_NIR000_DBraw.h5
100/100 - 85s - loss: 0.6449 - tp: 255.0000 - fp: 120.0000 - tn: 380.0000 - fn: 245.0000 - acc: 0.6350 - auc: 0.7027 - val_loss: 0.6752 - val_tp: 94.0000 - val_fp: 44.0000 - val_tn: 201.0000 - val_fn: 151.0000 - val_acc: 0.6020 - val_auc: 0.6415
Learning rate:  0.0001
Epoch 85/200
