GPU found. Num GPUs Available:  2
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]
Logical GPU found. Num logical GPUs Available:  2
[LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:0', device_type='GPU'), LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:1', device_type='GPU')]
Physical CPU found. Num Physical CPUs Available:  1
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Logical CPU found. Num logical CPUs Available:  1
[LogicalDevice(name='/job:localhost/replica:0/task:0/device:CPU:0', device_type='CPU')]

Configuration file:

Section: general
  workdir = /home/epfl/dforero/gravitational_lens_ml/
  train_multiband = /home/epfl/dforero/gravitational_lens_ml/data/train_multiband_noclip_bin
  binary = 1
  use_gpu = 1
Section: trainparams
  test_fraction = 0.33
  batch_size = 10
  subsample_train = 6000
  epochs = 130
  n = 3
  resnetversion = 2
  augment_train_data = 1
  data_bias = raw
  lens_nolens_ratio = 0.5
  kernel_size_1 = 8
  kernel_size_2 = 6
  dropout_kind = Dropout
Section: bands
  vis0 = 1
  nir1 = 0
  nir2 = 0
  nir3 = 0
Project directory: /home/epfl/dforero/gravitational_lens_ml/
The shape of the image catalog: (100009, 26)

The number of objects in the whole training sample is:  66993
The number of objects in the whole validation sample is:  32998
The test fraction is:  0.33
The number of objects in the training subsample is:  6000
The number of objects in the validation subsample is:  2955
The number of training steps is:  600
The number of validation steps is:  295
The bands are:  [True, False, False, False]
Learning rate:  0.001
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 200, 200, 1) 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 200, 200, 16) 160         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 200, 200, 16) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 200, 200, 16) 272         activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 200, 200, 16) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 200, 200, 16) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 200, 200, 64) 1088        activation[0][0]                 
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 200, 200, 64) 1088        activation_2[0][0]               
__________________________________________________________________________________________________
add (Add)                       (None, 200, 200, 64) 0           conv2d_4[0][0]                   
                                                                 conv2d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 200, 200, 64) 256         add[0][0]                        
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 200, 200, 64) 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 200, 200, 16) 1040        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 200, 200, 16) 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 200, 200, 16) 0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 200, 200, 64) 1088        activation_5[0][0]               
__________________________________________________________________________________________________
add_1 (Add)                     (None, 200, 200, 64) 0           add[0][0]                        
                                                                 conv2d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 200, 200, 64) 256         add_1[0][0]                      
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 200, 200, 64) 0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 200, 200, 16) 1040        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 200, 200, 16) 64          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 200, 200, 16) 0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 200, 200, 16) 2320        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 200, 200, 16) 64          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 200, 200, 16) 0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 200, 200, 64) 1088        activation_8[0][0]               
__________________________________________________________________________________________________
add_2 (Add)                     (None, 200, 200, 64) 0           add_1[0][0]                      
                                                                 conv2d_10[0][0]                  
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 200, 200, 64) 256         add_2[0][0]                      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 200, 200, 64) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 100, 100, 64) 4160        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 100, 100, 64) 256         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 100, 100, 64) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 100, 100, 64) 36928       activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 100, 100, 64) 256         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 100, 100, 64) 0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 100, 100, 128 8320        add_2[0][0]                      
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 100, 100, 128 8320        activation_11[0][0]              
__________________________________________________________________________________________________
add_3 (Add)                     (None, 100, 100, 128 0           conv2d_14[0][0]                  
                                                                 conv2d_13[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 100, 100, 128 512         add_3[0][0]                      
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 100, 100, 128 0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 100, 100, 64) 8256        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 100, 100, 64) 256         conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 100, 100, 64) 0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 100, 100, 64) 36928       activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 100, 100, 64) 256         conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 100, 100, 64) 0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 100, 100, 128 8320        activation_14[0][0]              
__________________________________________________________________________________________________
add_4 (Add)                     (None, 100, 100, 128 0           add_3[0][0]                      
                                                                 conv2d_17[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 100, 100, 128 512         add_4[0][0]                      
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 100, 100, 128 0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 100, 100, 64) 8256        activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 100, 100, 64) 256         conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 100, 100, 64) 0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 100, 100, 64) 36928       activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 100, 100, 64) 256         conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 100, 100, 64) 0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 100, 100, 128 8320        activation_17[0][0]              
__________________________________________________________________________________________________
add_5 (Add)                     (None, 100, 100, 128 0           add_4[0][0]                      
                                                                 conv2d_20[0][0]                  
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 100, 100, 128 512         add_5[0][0]                      
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 100, 100, 128 0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 50, 50, 128)  16512       activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 50, 50, 128)  512         conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 50, 50, 128)  0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 50, 50, 128)  147584      activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 50, 50, 128)  512         conv2d_22[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 50, 50, 128)  0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 50, 50, 256)  33024       add_5[0][0]                      
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 50, 50, 256)  33024       activation_20[0][0]              
__________________________________________________________________________________________________
add_6 (Add)                     (None, 50, 50, 256)  0           conv2d_24[0][0]                  
                                                                 conv2d_23[0][0]                  
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 50, 50, 256)  1024        add_6[0][0]                      
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 50, 50, 256)  0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 50, 50, 128)  32896       activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 50, 50, 128)  512         conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 50, 50, 128)  0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 50, 50, 128)  147584      activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 50, 50, 128)  512         conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 50, 50, 128)  0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 50, 50, 256)  33024       activation_23[0][0]              
__________________________________________________________________________________________________
add_7 (Add)                     (None, 50, 50, 256)  0           add_6[0][0]                      
                                                                 conv2d_27[0][0]                  
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 50, 50, 256)  1024        add_7[0][0]                      
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 50, 50, 256)  0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 50, 50, 128)  32896       activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 50, 50, 128)  512         conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 50, 50, 128)  0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 50, 50, 128)  147584      activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 50, 50, 128)  512         conv2d_29[0][0]                  
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 50, 50, 128)  0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 50, 50, 256)  33024       activation_26[0][0]              
__________________________________________________________________________________________________
add_8 (Add)                     (None, 50, 50, 256)  0           add_7[0][0]                      
                                                                 conv2d_30[0][0]                  
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 50, 50, 256)  1024        add_8[0][0]                      
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 50, 50, 256)  0           batch_normalization_27[0][0]     
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 6, 6, 256)    0           activation_27[0][0]              
__________________________________________________________________________________________________
flatten (Flatten)               (None, 9216)         0           average_pooling2d[0][0]          
__________________________________________________________________________________________________
dense (Dense)                   (None, 1)            9217        flatten[0][0]                    
==================================================================================================
Total params: 855,361
Trainable params: 850,145
Non-trainable params: 5,216
__________________________________________________________________________________________________
The model name is:  RN29v2_Tr6000_Te2955_bs10_ep130_aug1_VIS1_NIR000_DBraw_ratio0.5.h5
Using the raw bias (no weights applied).
Using weights: {0: 1.0, 1: 1.0}
Train the ResNet using real-time data augmentation.
Learning rate:  0.001
Epoch 1/130

Epoch 00001: val_acc improved from -inf to 0.50000, saving model to /home/epfl/dforero/gravitational_lens_ml/results/checkpoints/resnet/RN29v2_Tr6000_Te2955_bs10_ep130_aug1_VIS1_NIR000_DBraw_ratio0.5.h5
600/600 - 429s - loss: 1.1578 - tp: 1490.0000 - fp: 1484.0000 - tn: 1516.0000 - fn: 1510.0000 - acc: 0.5010 - auc: 0.5010 - val_loss: 0.9792 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 2/130

Epoch 00002: val_acc did not improve from 0.50000
600/600 - 423s - loss: 0.8895 - tp: 1442.0000 - fp: 1384.0000 - tn: 1616.0000 - fn: 1558.0000 - acc: 0.5097 - auc: 0.5152 - val_loss: 0.8259 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 3/130

Epoch 00003: val_acc did not improve from 0.50000
600/600 - 448s - loss: 0.7908 - tp: 1440.0000 - fp: 1303.0000 - tn: 1697.0000 - fn: 1560.0000 - acc: 0.5228 - auc: 0.5351 - val_loss: 0.7683 - val_tp: 1475.0000 - val_fp: 1475.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 4/130

Epoch 00004: val_acc did not improve from 0.50000
600/600 - 437s - loss: 0.7486 - tp: 1440.0000 - fp: 1267.0000 - tn: 1733.0000 - fn: 1560.0000 - acc: 0.5288 - auc: 0.5451 - val_loss: 0.7471 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 5/130

Epoch 00005: val_acc did not improve from 0.50000
600/600 - 458s - loss: 0.7271 - tp: 1478.0000 - fp: 1230.0000 - tn: 1770.0000 - fn: 1522.0000 - acc: 0.5413 - auc: 0.5607 - val_loss: 0.7314 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 6/130

Epoch 00006: val_acc did not improve from 0.50000
600/600 - 410s - loss: 0.7201 - tp: 1285.0000 - fp: 1146.0000 - tn: 1854.0000 - fn: 1715.0000 - acc: 0.5232 - auc: 0.5350 - val_loss: 0.7219 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 7/130

Epoch 00007: val_acc did not improve from 0.50000
600/600 - 442s - loss: 0.7165 - tp: 1153.0000 - fp: 1026.0000 - tn: 1974.0000 - fn: 1847.0000 - acc: 0.5212 - auc: 0.5297 - val_loss: 0.7163 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 8/130

Epoch 00008: val_acc did not improve from 0.50000
600/600 - 421s - loss: 0.7074 - tp: 1170.0000 - fp: 900.0000 - tn: 2100.0000 - fn: 1830.0000 - acc: 0.5450 - auc: 0.5513 - val_loss: 0.7126 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 9/130

Epoch 00009: val_acc did not improve from 0.50000
600/600 - 437s - loss: 0.7017 - tp: 1230.0000 - fp: 956.0000 - tn: 2044.0000 - fn: 1770.0000 - acc: 0.5457 - auc: 0.5643 - val_loss: 0.7141 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 10/130

Epoch 00010: val_acc did not improve from 0.50000
600/600 - 423s - loss: 0.6969 - tp: 1183.0000 - fp: 857.0000 - tn: 2143.0000 - fn: 1817.0000 - acc: 0.5543 - auc: 0.5704 - val_loss: 0.7140 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 11/130

Epoch 00011: val_acc did not improve from 0.50000
600/600 - 430s - loss: 0.6954 - tp: 1178.0000 - fp: 867.0000 - tn: 2133.0000 - fn: 1822.0000 - acc: 0.5518 - auc: 0.5723 - val_loss: 0.7114 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 12/130

Epoch 00012: val_acc did not improve from 0.50000
600/600 - 423s - loss: 0.6946 - tp: 1156.0000 - fp: 812.0000 - tn: 2188.0000 - fn: 1844.0000 - acc: 0.5573 - auc: 0.5762 - val_loss: 0.7108 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 13/130

Epoch 00013: val_acc did not improve from 0.50000
600/600 - 429s - loss: 0.6894 - tp: 1153.0000 - fp: 772.0000 - tn: 2228.0000 - fn: 1847.0000 - acc: 0.5635 - auc: 0.5874 - val_loss: 0.7118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 14/130

Epoch 00014: val_acc did not improve from 0.50000
600/600 - 426s - loss: 0.6904 - tp: 1252.0000 - fp: 860.0000 - tn: 2140.0000 - fn: 1748.0000 - acc: 0.5653 - auc: 0.5848 - val_loss: 0.7163 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 15/130

Epoch 00015: val_acc did not improve from 0.50000
600/600 - 423s - loss: 0.6798 - tp: 1268.0000 - fp: 817.0000 - tn: 2183.0000 - fn: 1732.0000 - acc: 0.5752 - auc: 0.6133 - val_loss: 0.7130 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.4969
Learning rate:  0.001
Epoch 16/130

Epoch 00016: val_acc did not improve from 0.50000
600/600 - 450s - loss: 0.6925 - tp: 1280.0000 - fp: 875.0000 - tn: 2125.0000 - fn: 1720.0000 - acc: 0.5675 - auc: 0.5905 - val_loss: 0.7148 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 17/130

Epoch 00017: val_acc did not improve from 0.50000
600/600 - 427s - loss: 0.6810 - tp: 1347.0000 - fp: 873.0000 - tn: 2127.0000 - fn: 1653.0000 - acc: 0.5790 - auc: 0.6044 - val_loss: 0.7266 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 18/130

Epoch 00018: val_acc did not improve from 0.50000
600/600 - 470s - loss: 0.6796 - tp: 1277.0000 - fp: 785.0000 - tn: 2215.0000 - fn: 1723.0000 - acc: 0.5820 - auc: 0.6065 - val_loss: 0.7163 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 19/130

Epoch 00019: val_acc did not improve from 0.50000
600/600 - 449s - loss: 0.6794 - tp: 1239.0000 - fp: 765.0000 - tn: 2235.0000 - fn: 1761.0000 - acc: 0.5790 - auc: 0.6029 - val_loss: 0.7125 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 20/130

Epoch 00020: val_acc did not improve from 0.50000
600/600 - 442s - loss: 0.6785 - tp: 1265.0000 - fp: 775.0000 - tn: 2225.0000 - fn: 1735.0000 - acc: 0.5817 - auc: 0.6136 - val_loss: 0.7172 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 21/130

Epoch 00021: val_acc did not improve from 0.50000
600/600 - 426s - loss: 0.6789 - tp: 1192.0000 - fp: 751.0000 - tn: 2249.0000 - fn: 1808.0000 - acc: 0.5735 - auc: 0.6020 - val_loss: 0.7168 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 22/130

Epoch 00022: val_acc did not improve from 0.50000
600/600 - 455s - loss: 0.6783 - tp: 1239.0000 - fp: 728.0000 - tn: 2272.0000 - fn: 1761.0000 - acc: 0.5852 - auc: 0.6139 - val_loss: 0.7174 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 23/130

Epoch 00023: val_acc did not improve from 0.50000
600/600 - 412s - loss: 0.6750 - tp: 1279.0000 - fp: 725.0000 - tn: 2275.0000 - fn: 1721.0000 - acc: 0.5923 - auc: 0.6166 - val_loss: 0.7168 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 24/130

Epoch 00024: val_acc did not improve from 0.50000
600/600 - 438s - loss: 0.6721 - tp: 1282.0000 - fp: 723.0000 - tn: 2277.0000 - fn: 1718.0000 - acc: 0.5932 - auc: 0.6247 - val_loss: 0.7199 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 25/130

Epoch 00025: val_acc did not improve from 0.50000
600/600 - 414s - loss: 0.6784 - tp: 1250.0000 - fp: 758.0000 - tn: 2242.0000 - fn: 1750.0000 - acc: 0.5820 - auc: 0.6053 - val_loss: 0.7104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 26/130

Epoch 00026: val_acc did not improve from 0.50000
600/600 - 458s - loss: 0.6718 - tp: 1326.0000 - fp: 716.0000 - tn: 2284.0000 - fn: 1674.0000 - acc: 0.6017 - auc: 0.6298 - val_loss: 0.7380 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 27/130

Epoch 00027: val_acc did not improve from 0.50000
600/600 - 418s - loss: 0.6729 - tp: 1260.0000 - fp: 691.0000 - tn: 2309.0000 - fn: 1740.0000 - acc: 0.5948 - auc: 0.6226 - val_loss: 0.7186 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 28/130

Epoch 00028: val_acc did not improve from 0.50000
600/600 - 431s - loss: 0.6666 - tp: 1234.0000 - fp: 683.0000 - tn: 2317.0000 - fn: 1766.0000 - acc: 0.5918 - auc: 0.6298 - val_loss: 0.7186 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 29/130

Epoch 00029: val_acc did not improve from 0.50000
600/600 - 424s - loss: 0.6631 - tp: 1324.0000 - fp: 715.0000 - tn: 2285.0000 - fn: 1676.0000 - acc: 0.6015 - auc: 0.6379 - val_loss: 0.7188 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 30/130

Epoch 00030: val_acc did not improve from 0.50000
600/600 - 427s - loss: 0.6651 - tp: 1358.0000 - fp: 724.0000 - tn: 2276.0000 - fn: 1642.0000 - acc: 0.6057 - auc: 0.6404 - val_loss: 0.7273 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 31/130

Epoch 00031: val_acc did not improve from 0.50000
600/600 - 437s - loss: 0.6619 - tp: 1278.0000 - fp: 670.0000 - tn: 2330.0000 - fn: 1722.0000 - acc: 0.6013 - auc: 0.6444 - val_loss: 0.7231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 32/130

Epoch 00032: val_acc did not improve from 0.50000
600/600 - 435s - loss: 0.6587 - tp: 1295.0000 - fp: 663.0000 - tn: 2337.0000 - fn: 1705.0000 - acc: 0.6053 - auc: 0.6393 - val_loss: 0.7299 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 33/130

Epoch 00033: val_acc did not improve from 0.50000
600/600 - 415s - loss: 0.6546 - tp: 1364.0000 - fp: 629.0000 - tn: 2371.0000 - fn: 1636.0000 - acc: 0.6225 - auc: 0.6591 - val_loss: 0.7374 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 34/130

Epoch 00034: val_acc did not improve from 0.50000
600/600 - 413s - loss: 0.6522 - tp: 1335.0000 - fp: 611.0000 - tn: 2389.0000 - fn: 1665.0000 - acc: 0.6207 - auc: 0.6564 - val_loss: 0.7242 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 35/130

Epoch 00035: val_acc did not improve from 0.50000
600/600 - 417s - loss: 0.6562 - tp: 1281.0000 - fp: 647.0000 - tn: 2353.0000 - fn: 1719.0000 - acc: 0.6057 - auc: 0.6472 - val_loss: 0.7245 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 36/130

Epoch 00036: val_acc did not improve from 0.50000
600/600 - 412s - loss: 0.6451 - tp: 1393.0000 - fp: 653.0000 - tn: 2347.0000 - fn: 1607.0000 - acc: 0.6233 - auc: 0.6729 - val_loss: 0.7267 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 37/130

Epoch 00037: val_acc did not improve from 0.50000
600/600 - 440s - loss: 0.6532 - tp: 1325.0000 - fp: 649.0000 - tn: 2351.0000 - fn: 1675.0000 - acc: 0.6127 - auc: 0.6522 - val_loss: 0.7319 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 38/130

Epoch 00038: val_acc did not improve from 0.50000
600/600 - 413s - loss: 0.6540 - tp: 1273.0000 - fp: 563.0000 - tn: 2437.0000 - fn: 1727.0000 - acc: 0.6183 - auc: 0.6630 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 39/130

Epoch 00039: val_acc did not improve from 0.50000
600/600 - 436s - loss: 0.6502 - tp: 1333.0000 - fp: 629.0000 - tn: 2371.0000 - fn: 1667.0000 - acc: 0.6173 - auc: 0.6547 - val_loss: 0.7234 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 40/130

Epoch 00040: val_acc did not improve from 0.50000
600/600 - 427s - loss: 0.6474 - tp: 1380.0000 - fp: 684.0000 - tn: 2316.0000 - fn: 1620.0000 - acc: 0.6160 - auc: 0.6659 - val_loss: 0.7283 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 41/130

Epoch 00041: val_acc did not improve from 0.50000
600/600 - 445s - loss: 0.6519 - tp: 1394.0000 - fp: 667.0000 - tn: 2333.0000 - fn: 1606.0000 - acc: 0.6212 - auc: 0.6600 - val_loss: 0.7248 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 42/130

Epoch 00042: val_acc did not improve from 0.50000
600/600 - 414s - loss: 0.6440 - tp: 1353.0000 - fp: 611.0000 - tn: 2389.0000 - fn: 1647.0000 - acc: 0.6237 - auc: 0.6720 - val_loss: 0.7255 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 43/130

Epoch 00043: val_acc did not improve from 0.50000
600/600 - 430s - loss: 0.6572 - tp: 1363.0000 - fp: 679.0000 - tn: 2321.0000 - fn: 1637.0000 - acc: 0.6140 - auc: 0.6523 - val_loss: 0.7254 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 44/130

Epoch 00044: val_acc did not improve from 0.50000
600/600 - 426s - loss: 0.6421 - tp: 1323.0000 - fp: 572.0000 - tn: 2428.0000 - fn: 1677.0000 - acc: 0.6252 - auc: 0.6673 - val_loss: 0.7227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 45/130

Epoch 00045: val_acc did not improve from 0.50000
600/600 - 438s - loss: 0.6515 - tp: 1277.0000 - fp: 620.0000 - tn: 2380.0000 - fn: 1723.0000 - acc: 0.6095 - auc: 0.6540 - val_loss: 0.7406 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 46/130

Epoch 00046: val_acc did not improve from 0.50000
600/600 - 431s - loss: 0.6523 - tp: 1264.0000 - fp: 616.0000 - tn: 2384.0000 - fn: 1736.0000 - acc: 0.6080 - auc: 0.6496 - val_loss: 0.7221 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 47/130

Epoch 00047: val_acc did not improve from 0.50000
600/600 - 430s - loss: 0.6428 - tp: 1347.0000 - fp: 607.0000 - tn: 2393.0000 - fn: 1653.0000 - acc: 0.6233 - auc: 0.6685 - val_loss: 0.7425 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 48/130

Epoch 00048: val_acc did not improve from 0.50000
600/600 - 435s - loss: 0.6444 - tp: 1326.0000 - fp: 604.0000 - tn: 2396.0000 - fn: 1674.0000 - acc: 0.6203 - auc: 0.6596 - val_loss: 0.7347 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 49/130

Epoch 00049: val_acc did not improve from 0.50000
600/600 - 416s - loss: 0.6419 - tp: 1301.0000 - fp: 592.0000 - tn: 2408.0000 - fn: 1699.0000 - acc: 0.6182 - auc: 0.6611 - val_loss: 0.7335 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 50/130

Epoch 00050: val_acc did not improve from 0.50000
600/600 - 453s - loss: 0.6498 - tp: 1327.0000 - fp: 620.0000 - tn: 2380.0000 - fn: 1673.0000 - acc: 0.6178 - auc: 0.6594 - val_loss: 0.7273 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 51/130

Epoch 00051: val_acc did not improve from 0.50000
600/600 - 423s - loss: 0.6426 - tp: 1332.0000 - fp: 578.0000 - tn: 2422.0000 - fn: 1668.0000 - acc: 0.6257 - auc: 0.6620 - val_loss: 0.7296 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 52/130

Epoch 00052: val_acc did not improve from 0.50000
600/600 - 442s - loss: 0.6451 - tp: 1338.0000 - fp: 604.0000 - tn: 2396.0000 - fn: 1662.0000 - acc: 0.6223 - auc: 0.6615 - val_loss: 0.7303 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 53/130

Epoch 00053: val_acc did not improve from 0.50000
600/600 - 421s - loss: 0.6524 - tp: 1206.0000 - fp: 524.0000 - tn: 2476.0000 - fn: 1794.0000 - acc: 0.6137 - auc: 0.6594 - val_loss: 0.7234 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 54/130

Epoch 00054: val_acc did not improve from 0.50000
600/600 - 433s - loss: 0.6584 - tp: 1280.0000 - fp: 640.0000 - tn: 2360.0000 - fn: 1720.0000 - acc: 0.6067 - auc: 0.6375 - val_loss: 0.7268 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 55/130

Epoch 00055: val_acc did not improve from 0.50000
600/600 - 419s - loss: 0.6416 - tp: 1348.0000 - fp: 582.0000 - tn: 2418.0000 - fn: 1652.0000 - acc: 0.6277 - auc: 0.6647 - val_loss: 0.7332 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 56/130

Epoch 00056: val_acc did not improve from 0.50000
600/600 - 443s - loss: 0.6494 - tp: 1331.0000 - fp: 623.0000 - tn: 2377.0000 - fn: 1669.0000 - acc: 0.6180 - auc: 0.6588 - val_loss: 0.7325 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 57/130

Epoch 00057: val_acc did not improve from 0.50000
600/600 - 432s - loss: 0.6400 - tp: 1335.0000 - fp: 590.0000 - tn: 2410.0000 - fn: 1665.0000 - acc: 0.6242 - auc: 0.6672 - val_loss: 0.7333 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 58/130

Epoch 00058: val_acc did not improve from 0.50000
600/600 - 442s - loss: 0.6441 - tp: 1333.0000 - fp: 593.0000 - tn: 2407.0000 - fn: 1667.0000 - acc: 0.6233 - auc: 0.6709 - val_loss: 0.7293 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 59/130

Epoch 00059: val_acc did not improve from 0.50000
600/600 - 431s - loss: 0.6433 - tp: 1365.0000 - fp: 595.0000 - tn: 2405.0000 - fn: 1635.0000 - acc: 0.6283 - auc: 0.6655 - val_loss: 0.7386 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 60/130

Epoch 00060: val_acc did not improve from 0.50000
600/600 - 436s - loss: 0.6401 - tp: 1387.0000 - fp: 614.0000 - tn: 2386.0000 - fn: 1613.0000 - acc: 0.6288 - auc: 0.6761 - val_loss: 0.7310 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 61/130

Epoch 00061: val_acc did not improve from 0.50000
600/600 - 432s - loss: 0.6431 - tp: 1366.0000 - fp: 624.0000 - tn: 2376.0000 - fn: 1634.0000 - acc: 0.6237 - auc: 0.6678 - val_loss: 0.7528 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 62/130

Epoch 00062: val_acc did not improve from 0.50000
600/600 - 443s - loss: 0.6297 - tp: 1418.0000 - fp: 580.0000 - tn: 2420.0000 - fn: 1582.0000 - acc: 0.6397 - auc: 0.6848 - val_loss: 0.7351 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 63/130

Epoch 00063: val_acc did not improve from 0.50000
600/600 - 416s - loss: 0.6328 - tp: 1387.0000 - fp: 594.0000 - tn: 2406.0000 - fn: 1613.0000 - acc: 0.6322 - auc: 0.6774 - val_loss: 0.7331 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 64/130

Epoch 00064: val_acc did not improve from 0.50000
600/600 - 419s - loss: 0.6387 - tp: 1245.0000 - fp: 539.0000 - tn: 2461.0000 - fn: 1755.0000 - acc: 0.6177 - auc: 0.6625 - val_loss: 0.7307 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 65/130

Epoch 00065: val_acc did not improve from 0.50000
600/600 - 429s - loss: 0.6375 - tp: 1321.0000 - fp: 589.0000 - tn: 2411.0000 - fn: 1679.0000 - acc: 0.6220 - auc: 0.6707 - val_loss: 0.7292 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 66/130

Epoch 00066: val_acc did not improve from 0.50000
600/600 - 425s - loss: 0.6392 - tp: 1307.0000 - fp: 522.0000 - tn: 2478.0000 - fn: 1693.0000 - acc: 0.6308 - auc: 0.6701 - val_loss: 0.7372 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 67/130

Epoch 00067: val_acc did not improve from 0.50000
600/600 - 445s - loss: 0.6412 - tp: 1321.0000 - fp: 586.0000 - tn: 2414.0000 - fn: 1679.0000 - acc: 0.6225 - auc: 0.6683 - val_loss: 0.7326 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 68/130

Epoch 00068: val_acc did not improve from 0.50000
600/600 - 429s - loss: 0.6404 - tp: 1374.0000 - fp: 634.0000 - tn: 2366.0000 - fn: 1626.0000 - acc: 0.6233 - auc: 0.6717 - val_loss: 0.7325 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 69/130

Epoch 00069: val_acc did not improve from 0.50000
600/600 - 448s - loss: 0.6394 - tp: 1384.0000 - fp: 623.0000 - tn: 2377.0000 - fn: 1616.0000 - acc: 0.6268 - auc: 0.6717 - val_loss: 0.7351 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 70/130

Epoch 00070: val_acc did not improve from 0.50000
600/600 - 418s - loss: 0.6349 - tp: 1363.0000 - fp: 567.0000 - tn: 2433.0000 - fn: 1637.0000 - acc: 0.6327 - auc: 0.6740 - val_loss: 0.7393 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 71/130

Epoch 00071: val_acc did not improve from 0.50000
600/600 - 429s - loss: 0.6382 - tp: 1388.0000 - fp: 620.0000 - tn: 2380.0000 - fn: 1612.0000 - acc: 0.6280 - auc: 0.6750 - val_loss: 0.7349 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 72/130

Epoch 00072: val_acc did not improve from 0.50000
600/600 - 437s - loss: 0.6372 - tp: 1370.0000 - fp: 598.0000 - tn: 2402.0000 - fn: 1630.0000 - acc: 0.6287 - auc: 0.6729 - val_loss: 0.7402 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 73/130

Epoch 00073: val_acc did not improve from 0.50000
600/600 - 426s - loss: 0.6372 - tp: 1340.0000 - fp: 559.0000 - tn: 2441.0000 - fn: 1660.0000 - acc: 0.6302 - auc: 0.6710 - val_loss: 0.7375 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 74/130

Epoch 00074: val_acc did not improve from 0.50000
600/600 - 429s - loss: 0.6395 - tp: 1384.0000 - fp: 605.0000 - tn: 2395.0000 - fn: 1616.0000 - acc: 0.6298 - auc: 0.6724 - val_loss: 0.7383 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 75/130

Epoch 00075: val_acc did not improve from 0.50000
600/600 - 426s - loss: 0.6314 - tp: 1458.0000 - fp: 663.0000 - tn: 2337.0000 - fn: 1542.0000 - acc: 0.6325 - auc: 0.6839 - val_loss: 0.7433 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 76/130

Epoch 00076: val_acc did not improve from 0.50000
600/600 - 416s - loss: 0.6408 - tp: 1398.0000 - fp: 613.0000 - tn: 2387.0000 - fn: 1602.0000 - acc: 0.6308 - auc: 0.6784 - val_loss: 0.7410 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 77/130

Epoch 00077: val_acc did not improve from 0.50000
600/600 - 431s - loss: 0.6340 - tp: 1384.0000 - fp: 606.0000 - tn: 2394.0000 - fn: 1616.0000 - acc: 0.6297 - auc: 0.6752 - val_loss: 0.7425 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 78/130

Epoch 00078: val_acc did not improve from 0.50000
600/600 - 419s - loss: 0.6281 - tp: 1422.0000 - fp: 563.0000 - tn: 2437.0000 - fn: 1578.0000 - acc: 0.6432 - auc: 0.6895 - val_loss: 0.7401 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 79/130

Epoch 00079: val_acc did not improve from 0.50000
600/600 - 461s - loss: 0.6318 - tp: 1372.0000 - fp: 558.0000 - tn: 2442.0000 - fn: 1628.0000 - acc: 0.6357 - auc: 0.6804 - val_loss: 0.7432 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 80/130

Epoch 00080: val_acc did not improve from 0.50000
600/600 - 452s - loss: 0.6357 - tp: 1323.0000 - fp: 543.0000 - tn: 2457.0000 - fn: 1677.0000 - acc: 0.6300 - auc: 0.6801 - val_loss: 0.7417 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.001
Epoch 81/130

Epoch 00081: val_acc did not improve from 0.50000
600/600 - 468s - loss: 0.6264 - tp: 1407.0000 - fp: 565.0000 - tn: 2435.0000 - fn: 1593.0000 - acc: 0.6403 - auc: 0.6879 - val_loss: 0.7421 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 82/130

Epoch 00082: val_acc did not improve from 0.50000
600/600 - 456s - loss: 0.6229 - tp: 1463.0000 - fp: 585.0000 - tn: 2415.0000 - fn: 1537.0000 - acc: 0.6463 - auc: 0.6992 - val_loss: 0.7438 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 83/130

Epoch 00083: val_acc did not improve from 0.50000
600/600 - 473s - loss: 0.6231 - tp: 1403.0000 - fp: 558.0000 - tn: 2442.0000 - fn: 1597.0000 - acc: 0.6408 - auc: 0.6907 - val_loss: 0.7432 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 84/130

Epoch 00084: val_acc did not improve from 0.50000
600/600 - 464s - loss: 0.6247 - tp: 1408.0000 - fp: 552.0000 - tn: 2448.0000 - fn: 1592.0000 - acc: 0.6427 - auc: 0.6892 - val_loss: 0.7424 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 85/130

Epoch 00085: val_acc did not improve from 0.50000
600/600 - 468s - loss: 0.6284 - tp: 1405.0000 - fp: 600.0000 - tn: 2400.0000 - fn: 1595.0000 - acc: 0.6342 - auc: 0.6860 - val_loss: 0.7434 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 86/130

Epoch 00086: val_acc did not improve from 0.50000
600/600 - 455s - loss: 0.6182 - tp: 1456.0000 - fp: 547.0000 - tn: 2453.0000 - fn: 1544.0000 - acc: 0.6515 - auc: 0.7015 - val_loss: 0.7503 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 87/130

Epoch 00087: val_acc did not improve from 0.50000
600/600 - 467s - loss: 0.6150 - tp: 1482.0000 - fp: 560.0000 - tn: 2440.0000 - fn: 1518.0000 - acc: 0.6537 - auc: 0.7055 - val_loss: 0.7568 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 88/130

Epoch 00088: val_acc did not improve from 0.50000
600/600 - 457s - loss: 0.6226 - tp: 1393.0000 - fp: 568.0000 - tn: 2432.0000 - fn: 1607.0000 - acc: 0.6375 - auc: 0.6912 - val_loss: 0.7514 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 89/130

Epoch 00089: val_acc did not improve from 0.50000
600/600 - 462s - loss: 0.6069 - tp: 1526.0000 - fp: 563.0000 - tn: 2437.0000 - fn: 1474.0000 - acc: 0.6605 - auc: 0.7213 - val_loss: 0.7467 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5017
Learning rate:  0.0001
Epoch 90/130

Epoch 00090: val_acc did not improve from 0.50000
600/600 - 457s - loss: 0.6196 - tp: 1475.0000 - fp: 596.0000 - tn: 2404.0000 - fn: 1525.0000 - acc: 0.6465 - auc: 0.6968 - val_loss: 0.7513 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 91/130

Epoch 00091: val_acc did not improve from 0.50000
600/600 - 453s - loss: 0.6075 - tp: 1512.0000 - fp: 540.0000 - tn: 2460.0000 - fn: 1488.0000 - acc: 0.6620 - auc: 0.7154 - val_loss: 0.7459 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 92/130

Epoch 00092: val_acc did not improve from 0.50000
600/600 - 451s - loss: 0.6180 - tp: 1496.0000 - fp: 584.0000 - tn: 2416.0000 - fn: 1504.0000 - acc: 0.6520 - auc: 0.7054 - val_loss: 0.7478 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 93/130

Epoch 00093: val_acc did not improve from 0.50000
600/600 - 470s - loss: 0.6118 - tp: 1476.0000 - fp: 561.0000 - tn: 2439.0000 - fn: 1524.0000 - acc: 0.6525 - auc: 0.7081 - val_loss: 0.7472 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 94/130

Epoch 00094: val_acc did not improve from 0.50000
600/600 - 461s - loss: 0.6110 - tp: 1497.0000 - fp: 544.0000 - tn: 2456.0000 - fn: 1503.0000 - acc: 0.6588 - auc: 0.7127 - val_loss: 0.7499 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 95/130

Epoch 00095: val_acc did not improve from 0.50000
600/600 - 463s - loss: 0.6054 - tp: 1502.0000 - fp: 541.0000 - tn: 2459.0000 - fn: 1498.0000 - acc: 0.6602 - auc: 0.7123 - val_loss: 0.7584 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 96/130

Epoch 00096: val_acc did not improve from 0.50000
600/600 - 455s - loss: 0.6144 - tp: 1458.0000 - fp: 558.0000 - tn: 2442.0000 - fn: 1542.0000 - acc: 0.6500 - auc: 0.7043 - val_loss: 0.7464 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 97/130

Epoch 00097: val_acc did not improve from 0.50000
600/600 - 459s - loss: 0.6060 - tp: 1515.0000 - fp: 523.0000 - tn: 2477.0000 - fn: 1485.0000 - acc: 0.6653 - auc: 0.7158 - val_loss: 0.7521 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5064
Learning rate:  0.0001
Epoch 98/130

Epoch 00098: val_acc did not improve from 0.50000
600/600 - 456s - loss: 0.6162 - tp: 1453.0000 - fp: 564.0000 - tn: 2436.0000 - fn: 1547.0000 - acc: 0.6482 - auc: 0.7013 - val_loss: 0.7467 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 99/130

Epoch 00099: val_acc did not improve from 0.50000
600/600 - 455s - loss: 0.6139 - tp: 1500.0000 - fp: 564.0000 - tn: 2436.0000 - fn: 1500.0000 - acc: 0.6560 - auc: 0.7058 - val_loss: 0.7440 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 100/130

Epoch 00100: val_acc did not improve from 0.50000
600/600 - 469s - loss: 0.6087 - tp: 1505.0000 - fp: 538.0000 - tn: 2462.0000 - fn: 1495.0000 - acc: 0.6612 - auc: 0.7187 - val_loss: 0.7438 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 101/130

Epoch 00101: val_acc did not improve from 0.50000
600/600 - 452s - loss: 0.6207 - tp: 1442.0000 - fp: 572.0000 - tn: 2428.0000 - fn: 1558.0000 - acc: 0.6450 - auc: 0.6960 - val_loss: 0.7404 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 102/130

Epoch 00102: val_acc did not improve from 0.50000
600/600 - 455s - loss: 0.6100 - tp: 1485.0000 - fp: 534.0000 - tn: 2466.0000 - fn: 1515.0000 - acc: 0.6585 - auc: 0.7090 - val_loss: 0.7396 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 103/130

Epoch 00103: val_acc did not improve from 0.50000
600/600 - 448s - loss: 0.6118 - tp: 1443.0000 - fp: 549.0000 - tn: 2451.0000 - fn: 1557.0000 - acc: 0.6490 - auc: 0.7028 - val_loss: 0.7465 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 104/130

Epoch 00104: val_acc did not improve from 0.50000
600/600 - 463s - loss: 0.6114 - tp: 1506.0000 - fp: 561.0000 - tn: 2439.0000 - fn: 1494.0000 - acc: 0.6575 - auc: 0.7067 - val_loss: 0.7402 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5017
Learning rate:  0.0001
Epoch 105/130

Epoch 00105: val_acc did not improve from 0.50000
600/600 - 457s - loss: 0.6096 - tp: 1508.0000 - fp: 564.0000 - tn: 2436.0000 - fn: 1492.0000 - acc: 0.6573 - auc: 0.7099 - val_loss: 0.7602 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 106/130

Epoch 00106: val_acc did not improve from 0.50000
600/600 - 463s - loss: 0.6108 - tp: 1486.0000 - fp: 543.0000 - tn: 2457.0000 - fn: 1514.0000 - acc: 0.6572 - auc: 0.7105 - val_loss: 0.7612 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 107/130

Epoch 00107: val_acc did not improve from 0.50000
600/600 - 459s - loss: 0.6034 - tp: 1504.0000 - fp: 506.0000 - tn: 2494.0000 - fn: 1496.0000 - acc: 0.6663 - auc: 0.7241 - val_loss: 0.7522 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 108/130

Epoch 00108: val_acc did not improve from 0.50000
600/600 - 464s - loss: 0.6076 - tp: 1507.0000 - fp: 571.0000 - tn: 2429.0000 - fn: 1493.0000 - acc: 0.6560 - auc: 0.7177 - val_loss: 0.7458 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 109/130

Epoch 00109: val_acc did not improve from 0.50000
600/600 - 453s - loss: 0.6067 - tp: 1516.0000 - fp: 558.0000 - tn: 2442.0000 - fn: 1484.0000 - acc: 0.6597 - auc: 0.7167 - val_loss: 0.7451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5010
Learning rate:  0.0001
Epoch 110/130

Epoch 00110: val_acc did not improve from 0.50000
600/600 - 477s - loss: 0.6107 - tp: 1515.0000 - fp: 593.0000 - tn: 2407.0000 - fn: 1485.0000 - acc: 0.6537 - auc: 0.7070 - val_loss: 0.7368 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.4949
Learning rate:  0.0001
Epoch 111/130

Epoch 00111: val_acc did not improve from 0.50000
600/600 - 453s - loss: 0.6071 - tp: 1515.0000 - fp: 559.0000 - tn: 2441.0000 - fn: 1485.0000 - acc: 0.6593 - auc: 0.7159 - val_loss: 0.7398 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5007
Learning rate:  0.0001
Epoch 112/130

Epoch 00112: val_acc did not improve from 0.50000
600/600 - 475s - loss: 0.6103 - tp: 1486.0000 - fp: 546.0000 - tn: 2454.0000 - fn: 1514.0000 - acc: 0.6567 - auc: 0.7140 - val_loss: 0.7446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 113/130

Epoch 00113: val_acc did not improve from 0.50000
600/600 - 465s - loss: 0.6019 - tp: 1553.0000 - fp: 558.0000 - tn: 2442.0000 - fn: 1447.0000 - acc: 0.6658 - auc: 0.7206 - val_loss: 0.7424 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5031
Learning rate:  0.0001
Epoch 114/130

Epoch 00114: val_acc did not improve from 0.50000
600/600 - 474s - loss: 0.6230 - tp: 1462.0000 - fp: 589.0000 - tn: 2411.0000 - fn: 1538.0000 - acc: 0.6455 - auc: 0.6936 - val_loss: 0.7410 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 115/130

Epoch 00115: val_acc did not improve from 0.50000
600/600 - 458s - loss: 0.6122 - tp: 1473.0000 - fp: 554.0000 - tn: 2446.0000 - fn: 1527.0000 - acc: 0.6532 - auc: 0.7065 - val_loss: 0.7442 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 116/130

Epoch 00116: val_acc did not improve from 0.50000
600/600 - 467s - loss: 0.6094 - tp: 1476.0000 - fp: 563.0000 - tn: 2437.0000 - fn: 1524.0000 - acc: 0.6522 - auc: 0.7106 - val_loss: 0.7466 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 117/130

Epoch 00117: val_acc did not improve from 0.50000
600/600 - 448s - loss: 0.5995 - tp: 1544.0000 - fp: 553.0000 - tn: 2447.0000 - fn: 1456.0000 - acc: 0.6652 - auc: 0.7250 - val_loss: 0.7462 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 118/130

Epoch 00118: val_acc did not improve from 0.50000
600/600 - 356s - loss: 0.6115 - tp: 1503.0000 - fp: 572.0000 - tn: 2428.0000 - fn: 1497.0000 - acc: 0.6552 - auc: 0.7078 - val_loss: 0.7475 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 119/130

Epoch 00119: val_acc did not improve from 0.50000
600/600 - 337s - loss: 0.6038 - tp: 1486.0000 - fp: 507.0000 - tn: 2493.0000 - fn: 1514.0000 - acc: 0.6632 - auc: 0.7184 - val_loss: 0.7475 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  0.0001
Epoch 120/130

Epoch 00120: val_acc did not improve from 0.50000
600/600 - 327s - loss: 0.6172 - tp: 1497.0000 - fp: 554.0000 - tn: 2446.0000 - fn: 1503.0000 - acc: 0.6572 - auc: 0.7052 - val_loss: 0.7545 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5095
Learning rate:  0.0001
Epoch 121/130

Epoch 00121: val_acc did not improve from 0.50000
600/600 - 343s - loss: 0.5964 - tp: 1580.0000 - fp: 554.0000 - tn: 2446.0000 - fn: 1420.0000 - acc: 0.6710 - auc: 0.7275 - val_loss: 0.7486 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  1e-05
Epoch 122/130

Epoch 00122: val_acc did not improve from 0.50000
600/600 - 332s - loss: 0.6132 - tp: 1450.0000 - fp: 539.0000 - tn: 2461.0000 - fn: 1550.0000 - acc: 0.6518 - auc: 0.7081 - val_loss: 0.7448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.4990
Learning rate:  1e-05
Epoch 123/130

Epoch 00123: val_acc did not improve from 0.50000
600/600 - 350s - loss: 0.6053 - tp: 1516.0000 - fp: 569.0000 - tn: 2431.0000 - fn: 1484.0000 - acc: 0.6578 - auc: 0.7109 - val_loss: 0.7423 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5017
Learning rate:  1e-05
Epoch 124/130

Epoch 00124: val_acc did not improve from 0.50000
600/600 - 327s - loss: 0.6078 - tp: 1546.0000 - fp: 589.0000 - tn: 2411.0000 - fn: 1454.0000 - acc: 0.6595 - auc: 0.7125 - val_loss: 0.7447 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.4997
Learning rate:  1e-05
Epoch 125/130

Epoch 00125: val_acc did not improve from 0.50000
600/600 - 324s - loss: 0.6022 - tp: 1572.0000 - fp: 557.0000 - tn: 2443.0000 - fn: 1428.0000 - acc: 0.6692 - auc: 0.7239 - val_loss: 0.7423 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  1e-05
Epoch 126/130

Epoch 00126: val_acc did not improve from 0.50000
600/600 - 334s - loss: 0.6052 - tp: 1530.0000 - fp: 596.0000 - tn: 2404.0000 - fn: 1470.0000 - acc: 0.6557 - auc: 0.7192 - val_loss: 0.7448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.4983
Learning rate:  1e-05
Epoch 127/130

Epoch 00127: val_acc did not improve from 0.50000
600/600 - 340s - loss: 0.6001 - tp: 1539.0000 - fp: 528.0000 - tn: 2472.0000 - fn: 1461.0000 - acc: 0.6685 - auc: 0.7257 - val_loss: 0.7458 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  1e-05
Epoch 128/130

Epoch 00128: val_acc did not improve from 0.50000
600/600 - 319s - loss: 0.5989 - tp: 1545.0000 - fp: 535.0000 - tn: 2465.0000 - fn: 1455.0000 - acc: 0.6683 - auc: 0.7238 - val_loss: 0.7469 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
Learning rate:  1e-05
Epoch 129/130

Epoch 00129: val_acc did not improve from 0.50000
600/600 - 330s - loss: 0.6053 - tp: 1541.0000 - fp: 553.0000 - tn: 2447.0000 - fn: 1459.0000 - acc: 0.6647 - auc: 0.7164 - val_loss: 0.7451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5044
Learning rate:  1e-05
Epoch 130/130

Epoch 00130: val_acc did not improve from 0.50000
600/600 - 332s - loss: 0.6047 - tp: 1518.0000 - fp: 556.0000 - tn: 2444.0000 - fn: 1482.0000 - acc: 0.6603 - auc: 0.7165 - val_loss: 0.7457 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 1475.0000 - val_fn: 1475.0000 - val_acc: 0.5000 - val_auc: 0.5000
295/295 - 82s - loss: 0.7457 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1475.0000 - fn: 1475.0000 - acc: 0.5000 - auc: 0.5000
Test loss: 0.7457451004092976
Test accuracy: 0.0
