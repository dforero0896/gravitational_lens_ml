GPU found. Num GPUs Available:  2
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]
Logical GPU found. Num logical GPUs Available:  2
[LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:0', device_type='GPU'), LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:1', device_type='GPU')]
Physical CPU found. Num Physical CPUs Available:  1
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Logical CPU found. Num logical CPUs Available:  1
[LogicalDevice(name='/job:localhost/replica:0/task:0/device:CPU:0', device_type='CPU')]

Configuration file:

Section: general
  workdir = /home/epfl/variu/phd/gravitational_lens_ml
  train_multiband = /home/epfl/dforero/gravitational_lens_ml/data/train_multiband_noclip_bin
  use_gpu = 1
Section: trainparams
  test_fraction = 0.33
  batch_size = 10
  subsample_train = 6000
  epochs = 130
  n = 3
  resnetversion = 1
  augment_train_data = 0
  data_bias = raw
Section: bands
  vis0 = 1
  nir1 = 0
  nir2 = 0
  nir3 = 0
Project directory: /home/epfl/variu/phd/gravitational_lens_ml
The shape of the image catalog: (100009, 26)

The number of objects in the whole training sample is:  66993
The number of objects in the whole validation sample is:  32998
The test fraction is:  0.33
The number of objects in the training subsample is:  6000
The number of objects in the validation subsample is:  2955
The number of training steps is:  600
The number of validation steps is:  295
The bands are:  [True, False, False, False]
Learning rate:  0.001
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 200, 200, 1) 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 200, 200, 16) 160         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 200, 200, 16) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 200, 200, 16) 2320        activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 200, 200, 16) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          conv2d_2[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 200, 200, 16) 0           activation[0][0]                 
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 200, 200, 16) 0           add[0][0]                        
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 200, 200, 16) 2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 200, 200, 16) 64          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 200, 200, 16) 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 200, 200, 16) 2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          conv2d_4[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 200, 200, 16) 0           activation_2[0][0]               
                                                                 batch_normalization_4[0][0]      
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 200, 200, 16) 0           add_1[0][0]                      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 200, 200, 16) 0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 200, 200, 16) 64          conv2d_6[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 200, 200, 16) 0           activation_4[0][0]               
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 200, 200, 16) 0           add_2[0][0]                      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 100, 100, 32) 4640        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 100, 100, 32) 128         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 100, 100, 32) 0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 100, 100, 32) 9248        activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 100, 100, 32) 544         activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 100, 100, 32) 128         conv2d_8[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, 100, 100, 32) 0           conv2d_9[0][0]                   
                                                                 batch_normalization_8[0][0]      
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 100, 100, 32) 0           add_3[0][0]                      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 100, 100, 32) 9248        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 100, 100, 32) 128         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 100, 100, 32) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 100, 100, 32) 9248        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 100, 100, 32) 128         conv2d_11[0][0]                  
__________________________________________________________________________________________________
add_4 (Add)                     (None, 100, 100, 32) 0           activation_8[0][0]               
                                                                 batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 100, 100, 32) 0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 100, 100, 32) 9248        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 100, 100, 32) 128         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 100, 100, 32) 0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 100, 100, 32) 9248        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 100, 100, 32) 128         conv2d_13[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 100, 100, 32) 0           activation_10[0][0]              
                                                                 batch_normalization_12[0][0]     
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 100, 100, 32) 0           add_5[0][0]                      
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 50, 50, 64)   18496       activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 50, 50, 64)   256         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 50, 50, 64)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 50, 50, 64)   36928       activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 50, 50, 64)   2112        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 50, 50, 64)   256         conv2d_15[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 50, 50, 64)   0           conv2d_16[0][0]                  
                                                                 batch_normalization_14[0][0]     
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 50, 50, 64)   0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 50, 50, 64)   36928       activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 50, 50, 64)   256         conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 50, 50, 64)   0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 50, 50, 64)   36928       activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 50, 50, 64)   256         conv2d_18[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 50, 50, 64)   0           activation_14[0][0]              
                                                                 batch_normalization_16[0][0]     
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 50, 50, 64)   0           add_7[0][0]                      
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 50, 50, 64)   36928       activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 50, 50, 64)   256         conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 50, 50, 64)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 50, 50, 64)   36928       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 50, 50, 64)   256         conv2d_20[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 50, 50, 64)   0           activation_16[0][0]              
                                                                 batch_normalization_18[0][0]     
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 50, 50, 64)   0           add_8[0][0]                      
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 6, 6, 64)     0           activation_18[0][0]              
__________________________________________________________________________________________________
dropout (Dropout)               (None, 6, 6, 64)     0           average_pooling2d[0][0]          
__________________________________________________________________________________________________
flatten (Flatten)               (None, 2304)         0           dropout[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 1)            2305        flatten[0][0]                    
==================================================================================================
Total params: 275,809
Trainable params: 274,433
Non-trainable params: 1,376
__________________________________________________________________________________________________
The model name is:  RN20v1_Tr6000_Te2955_bs10_ep130_aug0_VIS1_NIR000_DBraw_ratio0.5_dropout.h5
Using the raw bias (no weights applied).
Using weights: {0: 1.0, 1: 1.0}
Train the ResNet using real-time data augmentation.
Learning rate:  0.001
Epoch 1/130
Epoch 1/130

Epoch 00001: val_acc improved from -inf to 0.49695, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr6000_Te2955_bs10_ep130_aug0_VIS1_NIR000_DBraw_ratio0.5_dropout.h5
600/600 - 477s - loss: 0.8958 - tp: 1567.0000 - fp: 1524.0000 - tn: 1476.0000 - fn: 1433.0000 - acc: 0.5072 - auc: 0.5114 - val_loss: 0.8426 - val_tp: 14.0000 - val_fp: 23.0000 - val_tn: 1452.0000 - val_fn: 1461.0000 - val_acc: 0.4969 - val_auc: 0.4898
Learning rate:  0.001
Epoch 2/130
Epoch 1/130

Epoch 00002: val_acc improved from 0.49695 to 0.50814, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr6000_Te2955_bs10_ep130_aug0_VIS1_NIR000_DBraw_ratio0.5_dropout.h5
600/600 - 470s - loss: 0.8322 - tp: 1504.0000 - fp: 1467.0000 - tn: 1533.0000 - fn: 1496.0000 - acc: 0.5062 - auc: 0.5154 - val_loss: 0.8196 - val_tp: 608.0000 - val_fp: 584.0000 - val_tn: 891.0000 - val_fn: 867.0000 - val_acc: 0.5081 - val_auc: 0.5050
Learning rate:  0.001
Epoch 3/130
Epoch 1/130

Epoch 00003: val_acc improved from 0.50814 to 0.51627, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr6000_Te2955_bs10_ep130_aug0_VIS1_NIR000_DBraw_ratio0.5_dropout.h5
600/600 - 443s - loss: 0.8099 - tp: 1585.0000 - fp: 1460.0000 - tn: 1540.0000 - fn: 1415.0000 - acc: 0.5208 - auc: 0.5245 - val_loss: 0.8297 - val_tp: 978.0000 - val_fp: 930.0000 - val_tn: 545.0000 - val_fn: 497.0000 - val_acc: 0.5163 - val_auc: 0.5277
Learning rate:  0.001
Epoch 4/130
Epoch 1/130

Epoch 00004: val_acc did not improve from 0.51627
600/600 - 341s - loss: 0.7866 - tp: 1487.0000 - fp: 1413.0000 - tn: 1587.0000 - fn: 1513.0000 - acc: 0.5123 - auc: 0.5197 - val_loss: 0.7769 - val_tp: 114.0000 - val_fp: 71.0000 - val_tn: 1404.0000 - val_fn: 1361.0000 - val_acc: 0.5146 - val_auc: 0.4994
Learning rate:  0.001
Epoch 5/130
Epoch 1/130

Epoch 00005: val_acc did not improve from 0.51627
600/600 - 340s - loss: 0.7631 - tp: 1465.0000 - fp: 1317.0000 - tn: 1683.0000 - fn: 1535.0000 - acc: 0.5247 - auc: 0.5388 - val_loss: 1.2540 - val_tp: 1314.0000 - val_fp: 1295.0000 - val_tn: 180.0000 - val_fn: 161.0000 - val_acc: 0.5064 - val_auc: 0.5382
Learning rate:  0.001
Epoch 6/130
Epoch 1/130

Epoch 00006: val_acc improved from 0.51627 to 0.51661, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr6000_Te2955_bs10_ep130_aug0_VIS1_NIR000_DBraw_ratio0.5_dropout.h5
600/600 - 369s - loss: 0.7441 - tp: 1434.0000 - fp: 1257.0000 - tn: 1743.0000 - fn: 1566.0000 - acc: 0.5295 - auc: 0.5452 - val_loss: 0.7419 - val_tp: 193.0000 - val_fp: 144.0000 - val_tn: 1331.0000 - val_fn: 1282.0000 - val_acc: 0.5166 - val_auc: 0.5264
Learning rate:  0.001
Epoch 7/130
Epoch 1/130

Epoch 00007: val_acc improved from 0.51661 to 0.52542, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr6000_Te2955_bs10_ep130_aug0_VIS1_NIR000_DBraw_ratio0.5_dropout.h5
600/600 - 400s - loss: 0.7249 - tp: 1321.0000 - fp: 1067.0000 - tn: 1933.0000 - fn: 1679.0000 - acc: 0.5423 - auc: 0.5667 - val_loss: 0.7303 - val_tp: 640.0000 - val_fp: 565.0000 - val_tn: 910.0000 - val_fn: 835.0000 - val_acc: 0.5254 - val_auc: 0.5324
Learning rate:  0.001
Epoch 8/130
Epoch 1/130

Epoch 00008: val_acc did not improve from 0.52542
600/600 - 613s - loss: 0.7157 - tp: 1296.0000 - fp: 979.0000 - tn: 2021.0000 - fn: 1704.0000 - acc: 0.5528 - auc: 0.5755 - val_loss: 0.7296 - val_tp: 92.0000 - val_fp: 25.0000 - val_tn: 1450.0000 - val_fn: 1383.0000 - val_acc: 0.5227 - val_auc: 0.5284
Learning rate:  0.001
Epoch 9/130
Epoch 1/130

Epoch 00009: val_acc improved from 0.52542 to 0.56678, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr6000_Te2955_bs10_ep130_aug0_VIS1_NIR000_DBraw_ratio0.5_dropout.h5
600/600 - 360s - loss: 0.6967 - tp: 1332.0000 - fp: 853.0000 - tn: 2147.0000 - fn: 1668.0000 - acc: 0.5798 - auc: 0.6106 - val_loss: 0.7085 - val_tp: 727.0000 - val_fp: 530.0000 - val_tn: 945.0000 - val_fn: 748.0000 - val_acc: 0.5668 - val_auc: 0.5874
Learning rate:  0.001
Epoch 10/130
Epoch 1/130

Epoch 00010: val_acc did not improve from 0.56678
600/600 - 317s - loss: 0.6905 - tp: 1270.0000 - fp: 798.0000 - tn: 2202.0000 - fn: 1730.0000 - acc: 0.5787 - auc: 0.6094 - val_loss: 0.7022 - val_tp: 205.0000 - val_fp: 44.0000 - val_tn: 1431.0000 - val_fn: 1270.0000 - val_acc: 0.5546 - val_auc: 0.6013
Epoch 1/130
Learning rate:  0.001
Epoch 11/130
Epoch 1/130

Epoch 00011: val_acc improved from 0.56678 to 0.57356, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr6000_Te2955_bs10_ep130_aug0_VIS1_NIR000_DBraw_ratio0.5_dropout.h5
600/600 - 304s - loss: 0.6800 - tp: 1224.0000 - fp: 675.0000 - tn: 2325.0000 - fn: 1776.0000 - acc: 0.5915 - auc: 0.6322 - val_loss: 0.6959 - val_tp: 710.0000 - val_fp: 493.0000 - val_tn: 982.0000 - val_fn: 765.0000 - val_acc: 0.5736 - val_auc: 0.6020
Learning rate:  0.001
Epoch 12/130
Epoch 1/130

Epoch 00012: val_acc did not improve from 0.57356
600/600 - 393s - loss: 0.6719 - tp: 1402.0000 - fp: 725.0000 - tn: 2275.0000 - fn: 1598.0000 - acc: 0.6128 - auc: 0.6438 - val_loss: 0.7027 - val_tp: 315.0000 - val_fp: 170.0000 - val_tn: 1305.0000 - val_fn: 1160.0000 - val_acc: 0.5492 - val_auc: 0.6038
Learning rate:  0.001
Epoch 13/130
Epoch 1/130

Epoch 00013: val_acc improved from 0.57356 to 0.59525, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr6000_Te2955_bs10_ep130_aug0_VIS1_NIR000_DBraw_ratio0.5_dropout.h5
600/600 - 246s - loss: 0.6728 - tp: 1305.0000 - fp: 661.0000 - tn: 2339.0000 - fn: 1695.0000 - acc: 0.6073 - auc: 0.6405 - val_loss: 0.7170 - val_tp: 978.0000 - val_fp: 697.0000 - val_tn: 778.0000 - val_fn: 497.0000 - val_acc: 0.5953 - val_auc: 0.6431
Learning rate:  0.001
Epoch 14/130
Epoch 1/130

Epoch 00014: val_acc did not improve from 0.59525
600/600 - 492s - loss: 0.6677 - tp: 1374.0000 - fp: 705.0000 - tn: 2295.0000 - fn: 1626.0000 - acc: 0.6115 - auc: 0.6519 - val_loss: 0.7170 - val_tp: 850.0000 - val_fp: 653.0000 - val_tn: 822.0000 - val_fn: 625.0000 - val_acc: 0.5668 - val_auc: 0.5972
Learning rate:  0.001
Epoch 15/130
Epoch 1/130

Epoch 00015: val_acc did not improve from 0.59525
600/600 - 460s - loss: 0.6668 - tp: 1425.0000 - fp: 718.0000 - tn: 2282.0000 - fn: 1575.0000 - acc: 0.6178 - auc: 0.6575 - val_loss: 0.6927 - val_tp: 232.0000 - val_fp: 55.0000 - val_tn: 1420.0000 - val_fn: 1243.0000 - val_acc: 0.5600 - val_auc: 0.6326
Learning rate:  0.001
Epoch 16/130
Epoch 1/130

Epoch 00016: val_acc did not improve from 0.59525
600/600 - 520s - loss: 0.6590 - tp: 1404.0000 - fp: 712.0000 - tn: 2288.0000 - fn: 1596.0000 - acc: 0.6153 - auc: 0.6716 - val_loss: 0.7008 - val_tp: 732.0000 - val_fp: 455.0000 - val_tn: 1020.0000 - val_fn: 743.0000 - val_acc: 0.5939 - val_auc: 0.6272
Learning rate:  0.001
Epoch 17/130
Epoch 1/130

Epoch 00017: val_acc did not improve from 0.59525
600/600 - 296s - loss: 0.6463 - tp: 1509.0000 - fp: 679.0000 - tn: 2321.0000 - fn: 1491.0000 - acc: 0.6383 - auc: 0.6822 - val_loss: 0.7987 - val_tp: 1264.0000 - val_fp: 1075.0000 - val_tn: 400.0000 - val_fn: 211.0000 - val_acc: 0.5641 - val_auc: 0.6537
Learning rate:  0.001
Epoch 18/130
Epoch 1/130

Epoch 00018: val_acc improved from 0.59525 to 0.61390, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr6000_Te2955_bs10_ep130_aug0_VIS1_NIR000_DBraw_ratio0.5_dropout.h5
600/600 - 622s - loss: 0.6381 - tp: 1520.0000 - fp: 618.0000 - tn: 2382.0000 - fn: 1480.0000 - acc: 0.6503 - auc: 0.6985 - val_loss: 0.6643 - val_tp: 529.0000 - val_fp: 193.0000 - val_tn: 1282.0000 - val_fn: 946.0000 - val_acc: 0.6139 - val_auc: 0.6598
Learning rate:  0.001
Epoch 19/130
Epoch 1/130

Epoch 00019: val_acc did not improve from 0.61390
600/600 - 395s - loss: 0.6452 - tp: 1439.0000 - fp: 578.0000 - tn: 2422.0000 - fn: 1561.0000 - acc: 0.6435 - auc: 0.6837 - val_loss: 0.6812 - val_tp: 542.0000 - val_fp: 271.0000 - val_tn: 1204.0000 - val_fn: 933.0000 - val_acc: 0.5919 - val_auc: 0.6339
Learning rate:  0.001
Epoch 20/130
Epoch 1/130

Epoch 00020: val_acc improved from 0.61390 to 0.63186, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr6000_Te2955_bs10_ep130_aug0_VIS1_NIR000_DBraw_ratio0.5_dropout.h5
600/600 - 333s - loss: 0.6370 - tp: 1461.0000 - fp: 589.0000 - tn: 2411.0000 - fn: 1539.0000 - acc: 0.6453 - auc: 0.6943 - val_loss: 0.6789 - val_tp: 937.0000 - val_fp: 548.0000 - val_tn: 927.0000 - val_fn: 538.0000 - val_acc: 0.6319 - val_auc: 0.6874
Learning rate:  0.001
Epoch 21/130
Epoch 1/130

Epoch 00021: val_acc improved from 0.63186 to 0.64271, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr6000_Te2955_bs10_ep130_aug0_VIS1_NIR000_DBraw_ratio0.5_dropout.h5
600/600 - 392s - loss: 0.6388 - tp: 1538.0000 - fp: 623.0000 - tn: 2377.0000 - fn: 1462.0000 - acc: 0.6525 - auc: 0.7047 - val_loss: 0.6466 - val_tp: 859.0000 - val_fp: 438.0000 - val_tn: 1037.0000 - val_fn: 616.0000 - val_acc: 0.6427 - val_auc: 0.6954
Learning rate:  0.001
Epoch 22/130
Epoch 1/130

Epoch 00022: val_acc did not improve from 0.64271
600/600 - 1008s - loss: 0.6420 - tp: 1516.0000 - fp: 626.0000 - tn: 2374.0000 - fn: 1484.0000 - acc: 0.6483 - auc: 0.6984 - val_loss: 0.6532 - val_tp: 937.0000 - val_fp: 569.0000 - val_tn: 906.0000 - val_fn: 538.0000 - val_acc: 0.6247 - val_auc: 0.6891
Learning rate:  0.001
Epoch 23/130
Epoch 1/130

Epoch 00023: val_acc did not improve from 0.64271
600/600 - 446s - loss: 0.6404 - tp: 1497.0000 - fp: 641.0000 - tn: 2359.0000 - fn: 1503.0000 - acc: 0.6427 - auc: 0.6953 - val_loss: 0.6568 - val_tp: 452.0000 - val_fp: 85.0000 - val_tn: 1390.0000 - val_fn: 1023.0000 - val_acc: 0.6244 - val_auc: 0.6922
Learning rate:  0.001
Epoch 24/130
Epoch 1/130

Epoch 00024: val_acc did not improve from 0.64271
600/600 - 429s - loss: 0.6380 - tp: 1499.0000 - fp: 594.0000 - tn: 2406.0000 - fn: 1501.0000 - acc: 0.6508 - auc: 0.6943 - val_loss: 0.6625 - val_tp: 525.0000 - val_fp: 183.0000 - val_tn: 1292.0000 - val_fn: 950.0000 - val_acc: 0.6159 - val_auc: 0.6557
Learning rate:  0.001
Epoch 25/130
Epoch 1/130

Epoch 00025: val_acc did not improve from 0.64271
600/600 - 315s - loss: 0.6309 - tp: 1515.0000 - fp: 604.0000 - tn: 2396.0000 - fn: 1485.0000 - acc: 0.6518 - auc: 0.7068 - val_loss: 0.6426 - val_tp: 541.0000 - val_fp: 132.0000 - val_tn: 1343.0000 - val_fn: 934.0000 - val_acc: 0.6386 - val_auc: 0.7043
Learning rate:  0.001
Epoch 26/130
Epoch 1/130

Epoch 00026: val_acc did not improve from 0.64271
600/600 - 594s - loss: 0.6383 - tp: 1491.0000 - fp: 605.0000 - tn: 2395.0000 - fn: 1509.0000 - acc: 0.6477 - auc: 0.6949 - val_loss: 0.7186 - val_tp: 1049.0000 - val_fp: 824.0000 - val_tn: 651.0000 - val_fn: 426.0000 - val_acc: 0.5763 - val_auc: 0.6412
Learning rate:  0.001
Epoch 27/130
Epoch 1/130

Epoch 00027: val_acc did not improve from 0.64271
600/600 - 516s - loss: 0.6310 - tp: 1515.0000 - fp: 580.0000 - tn: 2420.0000 - fn: 1485.0000 - acc: 0.6558 - auc: 0.7080 - val_loss: 0.7269 - val_tp: 644.0000 - val_fp: 587.0000 - val_tn: 888.0000 - val_fn: 831.0000 - val_acc: 0.5193 - val_auc: 0.5393
Learning rate:  0.001
Epoch 28/130
Epoch 1/130

Epoch 00028: val_acc improved from 0.64271 to 0.64407, saving model to /home/epfl/variu/phd/gravitational_lens_ml/results/checkpoints/resnet/RN20v1_Tr6000_Te2955_bs10_ep130_aug0_VIS1_NIR000_DBraw_ratio0.5_dropout.h5
600/600 - 545s - loss: 0.6294 - tp: 1503.0000 - fp: 566.0000 - tn: 2434.0000 - fn: 1497.0000 - acc: 0.6562 - auc: 0.7076 - val_loss: 0.6346 - val_tp: 734.0000 - val_fp: 309.0000 - val_tn: 1166.0000 - val_fn: 741.0000 - val_acc: 0.6441 - val_auc: 0.7085
Learning rate:  0.001
Epoch 29/130
Epoch 1/130

Epoch 00029: val_acc did not improve from 0.64407
600/600 - 504s - loss: 0.6191 - tp: 1582.0000 - fp: 569.0000 - tn: 2431.0000 - fn: 1418.0000 - acc: 0.6688 - auc: 0.7236 - val_loss: 0.7000 - val_tp: 275.0000 - val_fp: 77.0000 - val_tn: 1398.0000 - val_fn: 1200.0000 - val_acc: 0.5671 - val_auc: 0.6078
